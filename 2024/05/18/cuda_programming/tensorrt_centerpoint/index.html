<!DOCTYPE html><html lang="zh-CN" data-theme="dark"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>TensorRT优化CenterPoint | Grapymage的个人博客</title><meta name="author" content="Grapymage"><meta name="copyright" content="Grapymage"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#0d0d0d"><meta name="description" content="项目地址 显卡是RTX2080S [toc] 环境安装 123456789101112131415conda create --name centerpoint python&#x3D;3.8conda activate centerpointpip install torch&#x3D;&#x3D;1.9.1+cu111 torchvision&#x3D;&#x3D;0.10.1+cu111 torchaudio&#x3D;&#x3D;0.9.1 -f https">
<meta property="og:type" content="article">
<meta property="og:title" content="TensorRT优化CenterPoint">
<meta property="og:url" content="https://zhangtingyu11.github.io/2024/05/18/cuda_programming/tensorrt_centerpoint/index.html">
<meta property="og:site_name" content="Grapymage的个人博客">
<meta property="og:description" content="项目地址 显卡是RTX2080S [toc] 环境安装 123456789101112131415conda create --name centerpoint python&#x3D;3.8conda activate centerpointpip install torch&#x3D;&#x3D;1.9.1+cu111 torchvision&#x3D;&#x3D;0.10.1+cu111 torchaudio&#x3D;&#x3D;0.9.1 -f https">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://zhangtingyu11.github.io/img/avatar.jpeg">
<meta property="article:published_time" content="2024-05-18T08:41:46.000Z">
<meta property="article:modified_time" content="2024-06-26T06:24:54.539Z">
<meta property="article:author" content="Grapymage">
<meta property="article:tag" content="TensorRT">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://zhangtingyu11.github.io/img/avatar.jpeg"><link rel="shortcut icon" href="/img/avatar.jpeg"><link rel="canonical" href="https://zhangtingyu11.github.io/2024/05/18/cuda_programming/tensorrt_centerpoint/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox/fancybox.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = {
  root: '/',
  algolia: undefined,
  localSearch: {"path":"/search.xml","preload":false,"top_n_per_article":1,"unescape":false,"languages":{"hits_empty":"找不到您查询的内容：${query}","hits_stats":"共找到 ${hits} 篇文章"}},
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlight.js","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  dateSuffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  infinitegrid: {
    js: 'https://cdn.jsdelivr.net/npm/@egjs/infinitegrid/dist/infinitegrid.min.js',
    buttonText: '加载更多'
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: false,
  },
  autoDarkmode: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'TensorRT优化CenterPoint',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2024-06-26 14:24:54'
}</script><script>(win=>{
      win.saveToLocal = {
        set: (key, value, ttl) => {
          if (ttl === 0) return
          const now = Date.now()
          const expiry = now + ttl * 86400000
          const item = {
            value,
            expiry
          }
          localStorage.setItem(key, JSON.stringify(item))
        },
      
        get: key => {
          const itemStr = localStorage.getItem(key)
      
          if (!itemStr) {
            return undefined
          }
          const item = JSON.parse(itemStr)
          const now = Date.now()
      
          if (now > item.expiry) {
            localStorage.removeItem(key)
            return undefined
          }
          return item.value
        }
      }
    
      win.getScript = (url, attr = {}) => new Promise((resolve, reject) => {
        const script = document.createElement('script')
        script.src = url
        script.async = true
        script.onerror = reject
        script.onload = script.onreadystatechange = function() {
          const loadState = this.readyState
          if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
          script.onload = script.onreadystatechange = null
          resolve()
        }

        Object.keys(attr).forEach(key => {
          script.setAttribute(key, attr[key])
        })

        document.head.appendChild(script)
      })
    
      win.getCSS = (url, id = false) => new Promise((resolve, reject) => {
        const link = document.createElement('link')
        link.rel = 'stylesheet'
        link.href = url
        if (id) link.id = id
        link.onerror = reject
        link.onload = link.onreadystatechange = function() {
          const loadState = this.readyState
          if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
          link.onload = link.onreadystatechange = null
          resolve()
        }
        document.head.appendChild(link)
      })
    
      win.activateDarkMode = () => {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = () => {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
        if (t === 'dark') activateDarkMode()
        else if (t === 'light') activateLightMode()
      
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
      const detectApple = () => {
        if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
          document.documentElement.classList.add('apple')
        }
      }
      detectApple()
    })(window)</script><meta name="generator" content="Hexo 7.0.0"><link href="https://cdn.bootcss.com/KaTeX/0.11.1/katex.min.css" rel="stylesheet" /></head><body><div id="web_bg"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="/img/avatar.jpeg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">119</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">66</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">56</div></a></div><hr class="custom-hr"/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fas fa-book"></i><span> 文章</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/archives/"><i class="fa-fw fas fa-file-archive"></i><span> 归档</span></a></li><li><a class="site-page child" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></li><li><a class="site-page child" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('/img/top_img.png')"><nav id="nav"><span id="blog-info"><a href="/" title="Grapymage的个人博客"><span class="site-name">Grapymage的个人博客</span></a></span><div id="menus"><div id="search-button"><a class="site-page social-icon search" href="javascript:void(0);"><i class="fas fa-search fa-fw"></i><span> 搜索</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fas fa-book"></i><span> 文章</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/archives/"><i class="fa-fw fas fa-file-archive"></i><span> 归档</span></a></li><li><a class="site-page child" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></li><li><a class="site-page child" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div><div id="toggle-menu"><a class="site-page" href="javascript:void(0);"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">TensorRT优化CenterPoint</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2024-05-18T08:41:46.000Z" title="发表于 2024-05-18 16:41:46">2024-05-18</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2024-06-26T06:24:54.539Z" title="更新于 2024-06-26 14:24:54">2024-06-26</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/TensorRT/">TensorRT</a><i class="fas fa-angle-right post-meta-separator"></i><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/TensorRT/CenterPoint/">CenterPoint</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">字数总计:</span><span class="word-count">12k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">阅读时长:</span><span>55分钟</span></span><span class="post-meta-separator">|</span><span id="" data-flag-title="TensorRT优化CenterPoint"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="twikoo_visitors"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><p><a href="">项目地址</a><br>
显卡是RTX2080S<br>
[toc]</p>
<h1 id="环境安装">环境安装</h1>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">conda create --name centerpoint python=3.8</span><br><span class="line">conda activate centerpoint</span><br><span class="line">pip install torch==1.9.1+cu111 torchvision==0.10.1+cu111 torchaudio==0.9.1 -f https://download.pytorch.org/whl/torch_stable.html</span><br><span class="line"></span><br><span class="line">git <span class="built_in">clone</span> https://github.com/tianweiy/CenterPoint.git</span><br><span class="line"><span class="built_in">cd</span> CenterPoint</span><br><span class="line"><span class="comment">#在这之前需要指定opencv-python和opencv-contrib-python的版本为4.2.0.34</span></span><br><span class="line">pip install -r requirements.txt</span><br><span class="line"></span><br><span class="line"><span class="comment"># add CenterPoint to PYTHONPATH by adding the following line to ~/.bashrc or ~/.zshrc(change the path accordingly)</span></span><br><span class="line"><span class="built_in">export</span> PYTHONPATH=<span class="string">&quot;<span class="variable">$&#123;PYTHONPATH&#125;</span>:PATH_TO_CENTERPOINT&quot;</span></span><br><span class="line"><span class="comment"># 运行之前需要删除det3d/ops/ 下面的所有的build文件夹</span></span><br><span class="line"><span class="built_in">cd</span> ..</span><br><span class="line"><span class="comment"># 将所有文件夹下的AT_CHECK换为TORCH_CHECK, 注意大小写</span></span><br><span class="line">bash setup.sh</span><br></pre></td></tr></table></figure>
<p>安装spconv</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">git <span class="built_in">clone</span> https://github.com/traveller59/spconv.git --recursive</span><br><span class="line"><span class="built_in">cd</span> spconv &amp;&amp; git checkout 7342772</span><br><span class="line"><span class="comment"># 需要将spconv/src/spconv/all.cc中的torch::jit::RegisterOperators改为torch::RegisterOperators</span></span><br><span class="line">python setup.py bdist_wheel</span><br><span class="line"><span class="built_in">cd</span> ./dist &amp;&amp; pip install *</span><br></pre></td></tr></table></figure>
<p>安装onnx</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 需要修改虚拟环境中的onnx_simplifier.py, 我的路径在/home/zty/anaconda3/envs/centerpoint-pytorch1.9/lib/python3.8/site-packages/onnxsim/onnx_simplifier.py, 将np.bool修改为np.bool_</span></span><br><span class="line">pip install onnx==1.16.0 onnx-simplifier==0.2.22 onnxruntime==1.17.3 onnxoptimizer==0.3.13</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h1 id="准备数据">准备数据</h1>
<p>下载<a target="_blank" rel="noopener" href="https://drive.google.com/drive/folders/1f8EHYqfHtP6kyNDlsTIG9Nbz_pJ0Cal9?usp=sharing">权重文件</a><br>
准备nuscenes数据集, 使用mini版本的就可以<br>
文件需要放在data文件夹下面, 参考下面的目录结构<br>
使用以下指令生成数据集的文件</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># nuScenes</span></span><br><span class="line">python tools/create_data.py nuscenes_data_prep --root_path=NUSCENES_TRAINVAL_DATASET_ROOT --version=<span class="string">&quot;v1.0-mini&quot;</span> --nsweeps=10</span><br></pre></td></tr></table></figure>
<p>最终的目录结构如下:</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"># For nuScenes Dataset </span><br><span class="line">└── CenterPoint</span><br><span class="line">       └── data    </span><br><span class="line">              └── nuScenes </span><br><span class="line">                     ├── samples       &lt;-- key frames</span><br><span class="line">                     ├── sweeps        &lt;-- frames without annotation</span><br><span class="line">                     ├── maps          &lt;-- unused</span><br><span class="line">                     |── v1.0-mini &lt;-- metadata and annotations</span><br><span class="line">                     |── infos_train_10sweeps_withvelo_filter_True.pkl &lt;-- train annotations</span><br><span class="line">                     |── infos_val_10sweeps_withvelo_filter_True.pkl &lt;-- val annotations</span><br><span class="line">                     |── dbinfos_train_10sweeps_withvelo.pkl &lt;-- GT database info files</span><br><span class="line">                     |── gt_database_10sweeps_withvelo &lt;-- GT database </span><br></pre></td></tr></table></figure>
<h1 id="导出onnx权重">导出Onnx权重</h1>
<p>运行以下指令</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python tools/export_pointpillars_onnx.py</span><br></pre></td></tr></table></figure>
<h2 id="读取数据">读取数据</h2>
<p>第一步是构建dataset和dataloader, 然后读取数据, 读取数据会有一个pipeline, 下面按照小标题依次进行解析</p>
<h3 id="loadpointcloudfromfile">LoadPointCloudFromFile</h3>
<p>nuscenes分为关键帧frame和非关键帧sweep, 关键帧是有标注数据的, 非关键帧没有标注数据.<br>
由于点云比较稀疏, 因此常规的操作是将关键帧和非关键帧的点云进行合并<br>
在之前创建数据集的时候, 会添加当前帧之前9帧的sweep(添加的时候需要计算之前的帧到当前帧的转换矩阵)<br>
如果当前帧前面有9帧点云, 直接添加<br>
如果当前帧前面没点云, 将自身复制9次添加<br>
如果当前帧前面的点云数不足9帧, 用添加的时间最远的一帧来填充</p>
<p>LoadPointCloudFromFile类做的事情就是<br>
将之前帧的点云打乱顺序, 和当前帧的点云进行拼接(<strong>个人理解, 是对点云进行了shuffle, 使得网络的训练遵从点云的无序性</strong>), 除了点云之外还拼接了每一帧点云的时间</p>
<h3 id="loadpointcloudannotations">LoadPointCloudAnnotations</h3>
<p>主要是加载标签, 标签包含以下几个<br>
boxes: <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>N</mi><mo>×</mo><mn>9</mn></mrow><annotation encoding="application/x-tex">N\times 9</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.76666em;vertical-align:-0.08333em;"></span><span class="mord mathdefault" style="margin-right:0.10903em;">N</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">9</span></span></span></span>的包围框, <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>N</mi></mrow><annotation encoding="application/x-tex">N</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.10903em;">N</span></span></span></span>表示包围框的个数, 9个维度分别为<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>x</mi><mo separator="true">,</mo><mi>y</mi><mo separator="true">,</mo><mi>z</mi><mo separator="true">,</mo><mi>w</mi><mo separator="true">,</mo><mi>l</mi><mo separator="true">,</mo><mi>h</mi><mo separator="true">,</mo><mi>θ</mi><mo separator="true">,</mo><msub><mi>v</mi><mi>x</mi></msub><mo separator="true">,</mo><msub><mi>v</mi><mi>y</mi></msub></mrow><annotation encoding="application/x-tex">x, y, z, w, l, h, \theta, v_x, v_y</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.980548em;vertical-align:-0.286108em;"></span><span class="mord mathdefault">x</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault" style="margin-right:0.03588em;">y</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault" style="margin-right:0.04398em;">z</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault" style="margin-right:0.02691em;">w</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault" style="margin-right:0.01968em;">l</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault">h</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault" style="margin-right:0.02778em;">θ</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">v</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">x</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">v</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.15139200000000003em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.03588em;">y</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span></span></span></span><br>
names: 长度为<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>N</mi></mrow><annotation encoding="application/x-tex">N</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.10903em;">N</span></span></span></span>的array, 存储每个包围框的类别, 类别为字符串形式<br>
tokens: 长度为<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>N</mi></mrow><annotation encoding="application/x-tex">N</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.10903em;">N</span></span></span></span>的array, 存储每个包围框的token<br>
velocities:  <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>N</mi><mo>×</mo><mn>3</mn></mrow><annotation encoding="application/x-tex">N\times 3</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.76666em;vertical-align:-0.08333em;"></span><span class="mord mathdefault" style="margin-right:0.10903em;">N</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">3</span></span></span></span>的速度, 一般只用前两维, 第三维不准确, 前两维和boxes存储的速度一致</p>
<h3 id="preprocess">Preprocess</h3>
<p>因为导出权重不需要训练, 所以这个类里面只进行了提取点云的操作</p>
<h3 id="voxelization">Voxelization</h3>
<p>输入有几个数据</p>
<ol>
<li>voxel的大小, 这边选用的是(0.2, 0.2, 8), 因为用的Centerpoint Pointpillar, 所以高度不做划分</li>
<li>点云范围, x设置的是(-51.2 ~ 51.2), y设置的是(-51.2 ~ 51.2)</li>
<li>网格大小, 分别为(512, 512, 1), 分别由点云范围除voxel大小得到</li>
<li>最多的非空voxel的个数, 测试阶段为60000个</li>
</ol>
<p>voxel的尺寸为(最多非空voxel个数(60000), 每个voxel中的最大点数(设置为20),  点云的特征(5, 包含xyz, 反射率和时间))<br>
除了voxel外还需要记录一些数据, voxel_num为非空voxel的个数, num_points_per_voxel为每个voxel中的点数, coors为每个voxel在空间中的索引</p>
<p><strong>voxelization的具体操作</strong></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">创建一个全部为0的voxels, 尺寸为(最多非空voxel个数(60000), 每个体素中的最大点数(设置为20),  点云的特征(5, 包含xyz, 反射率和时间))</span><br><span class="line">创建一个全是-1的数组, 记录空间索引为(i, j, k)的体素在voxels中的索引, 记为coor_to_voxelidx</span><br><span class="line">创建一个长度为(最多非空voxel个数(60000), 3)的coor数组, 用于记录每个体素对应的空间索引</span><br><span class="line">创建一个长度为最多非空voxel个数(60000)的num_points_per_voxel数组, 用于记录每个体素中点的个数</span><br><span class="line"></span><br><span class="line">初始化voxel_num为0</span><br><span class="line">遍历点云中的每个点point</span><br><span class="line">计算该点所在的体素的空间索引</span><br><span class="line">如果这个空间索引在coor_to_voxelidx中记录的索引值为-1, 说明这个体素原先没有点</span><br><span class="line">那么这个体素的索引值就是voxel_num</span><br><span class="line">如果voxel_num大于设置的最大非空体素个数就跳过</span><br><span class="line">否则将voxel_num+1, 并且更新空间索引为(i, j, k)的体素在voxels中的索引, 即更新coor_to_voxelidx[i][j][k] = voxel_num-1, 同时更新coors[coor_to_voxelidx[i][j][k]] = (i, j, k)</span><br><span class="line"></span><br><span class="line">获取当前体素中的点云数, 为num_points_per_voxel[voxel_num-1], 记为num</span><br><span class="line">如果这个个数小于每个体素设置的最大点数</span><br><span class="line">就将voxels[voxel_num-1, num] = point</span><br><span class="line">并且更新每个voxel中的点数, num_points_per_voxel[voxel_num-1]+=1</span><br><span class="line"></span><br><span class="line">最后会得到一个voxel_num, 即非空voxel的个数</span><br><span class="line">将coors, voxels, num_points_per_voxel都只取前voxel_num个</span><br><span class="line">最后得到的张量尺寸</span><br><span class="line">coors: (voxel_num, 3)</span><br><span class="line">voxels: (voxel_num, 每个体素中的最大点数(20), 点云的特征(5))</span><br><span class="line">num_points_per_voxel: (voxel_num)</span><br></pre></td></tr></table></figure>
<h3 id="assignlabel">AssignLabel</h3>
<p>因为是测试阶段, 所以不会分配标签</p>
<h3 id="reformat">Reformat</h3>
<p>将前面的输出都集合成一个字典<br>
字典里面包括以下信息:</p>
<ul>
<li>‘metadata’: 记录元数据, 包括图片文件夹的前缀, 点云特征的个数, 图片的token</li>
<li>‘points’: (N, 5)的点云, 其中N为点云的个数</li>
<li>‘voxels’: (非空voxel个数, voxel中的最大点数, 5)的voxel数据</li>
<li>‘shape’: 网格的尺寸, 为(512, 512, 1)</li>
<li>‘num_points’: (非空voxel个数), 记录每个非空voxel中的点数</li>
<li>‘num_voxels’: (1), 记录非空voxel个数</li>
<li>‘coordinates’: (非空voxel个数, 3), 记录每个非空voxel在空间中的坐标</li>
</ul>
<p><mark style="background: #ff6666">其中上面的这些预处理操作用处并不大, 只是提供了一个尺寸依据, 后面会根据这些尺寸来构建导出模型所使用的数据</mark></p>
<h2 id="将数据放入gpu中">将数据放入GPU中</h2>
<p>主要执行的函数是<code>example_to_device</code>函数<br>
将<code>voxels</code>, <code>coordinates</code>, <code>num_points</code>, <code>points</code>, <code>num_voxels</code>放入GPU上</p>
<h2 id="创建模拟数据">创建模拟数据</h2>
<p>将创建一个全新的尺寸为(非空voxel个数, voxel中的最多点数, 10)的voxel张量, 替换原来的voxel<br>
原因是pointpillars中的特征为<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>x</mi><mo separator="true">,</mo><mi>y</mi><mo separator="true">,</mo><mi>c</mi><mo separator="true">,</mo><mi>r</mi><mo separator="true">,</mo><msub><mi>x</mi><mi>c</mi></msub><mo separator="true">,</mo><msub><mi>y</mi><mi>c</mi></msub><mo separator="true">,</mo><msub><mi>x</mi><mi>p</mi></msub><mo separator="true">,</mo><msub><mi>y</mi><mi>p</mi></msub><mo separator="true">,</mo><mi>t</mi></mrow><annotation encoding="application/x-tex">x, y, c, r, x_c, y_c, x_p, y_p, t</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.9011879999999999em;vertical-align:-0.286108em;"></span><span class="mord mathdefault">x</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault" style="margin-right:0.03588em;">y</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault">c</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault" style="margin-right:0.02778em;">r</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">c</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">c</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.15139200000000003em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">p</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.15139200000000003em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">p</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault">t</span></span></span></span><br>
其中<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mo>∗</mo><mi>c</mi></msub></mrow><annotation encoding="application/x-tex">*_c</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.61528em;vertical-align:-0.15em;"></span><span class="mord"><span class="mbin">∗</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">c</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>为到pillars中的算术平均点的距离, <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mo>∗</mo><mi>p</mi></msub></mrow><annotation encoding="application/x-tex">*_p</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.751388em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mbin">∗</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.15139200000000003em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">p</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span></span></span></span>为到pillars中心的距离, <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>t</mi></mrow><annotation encoding="application/x-tex">t</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.61508em;vertical-align:0em;"></span><span class="mord mathdefault">t</span></span></span></span>为时间. 总共是10个维度</p>
<h2 id="pillarfeatureextraction部分的模型介绍">PillarFeatureExtraction部分的模型介绍</h2>
<p>以下从模型的数据流角度依次讲解每个模块的输入输出</p>
<h3 id="pillarfeaturenet">PillarFeatureNet</h3>
<p>输入是尺寸为(非空voxel个数, voxel中的最大点数, 10)的voxel数据<br>
<mark style="background: #2ea8e5">第一个PFN层</mark></p>
<ol>
<li>经过一个10-&gt;32的全连接层, 一个BatchNorm1d, 一个ReLU,</li>
<li>对第一个维度(voxel中的最大点数)求最大值, 得到尺寸(非空voxel个数, 1, 32)的张量</li>
<li>repeat得到尺寸为(非空voxel个数, voxel中的最大点数, 32)的张量</li>
<li>将该张量与原始张量进行拼接, 得到(非空voxel个数, voxel中的最大点数, 64)的张量</li>
</ol>
<p><mark style="background: #2ea8e5">第二个PFN层</mark></p>
<ol>
<li>经过一个64-&gt;64的全连接层, 一个BatchNorm1d, 一个ReLU</li>
<li>对第一个维度(voxel中的最大点数)求最大值, 得到尺寸(非空voxel个数, 1, 64)的张量</li>
<li>返回这个张量</li>
</ol>
<p>最后的输出会对第一维进行压缩, 即, 输出的尺寸为(非空voxel个数, 64)</p>
<h2 id="导出pillarfeatureextraction部分模型">导出PillarFeatureExtraction部分模型</h2>
<p>模型导出的代码如下</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.onnx.export(model.reader, (example[<span class="string">&quot;voxels&quot;</span>],example[<span class="string">&quot;num_voxels&quot;</span>],example[<span class="string">&quot;coordinates&quot;</span>]),<span class="string">&quot;onnx_model/pfe.onnx&quot;</span>,opset_version=<span class="number">11</span>)</span><br></pre></td></tr></table></figure>
<p>其中<code>model.reader</code>就是前面介绍的PillarFeatureExtraction部分, 输入信息包括voxels, 非空voxel个数, 每个非空voxel的中间坐标, 和PillarFeatureExtraction的输入一致</p>
<h2 id="没有导出的部分-pointpillarsscatter介绍">没有导出的部分(PointPillarsScatter介绍)</h2>
<p>这一部分是因为TensorRT不支持这种操作<br>
这个函数的目的就是将所有的voxel特征还原到BEV特征<br>
具体的操作如下:</p>
<ol>
<li>遍历每一个batch, 创建一个尺寸为(64, 512*512)的全零张量<code>canvas</code></li>
<li>对于batch中的数据. 因为之前记录了每个voxel的索引, [batchidx, xidx, yidx, zidx], 所以找到和当前batchidx对应的数据</li>
<li>同时zidx一定是0, 因为没有对高度进行划分, 那么可以根据xidx和yidx将索引转化成一维的, 根据这个一维索引对<code>canvas</code>进行赋值</li>
<li>将<code>canvas</code>加入列表中</li>
<li>对列表中的<code>canvas</code>在batch维度上进行拼接, 得到<code>batch_canvas</code></li>
<li>将<code>batch_canvas</code>的形状变为(batch_size, 64, 512, 512)</li>
</ol>
<h2 id="rpn部分模型介绍">RPN部分模型介绍</h2>
<h3 id="rpn">RPN</h3>
<p>RPN是Block和DeBlock的结构, 下面按照Block, DeBlock的顺序进行解析</p>
<h4 id="block1">Block1</h4>
<p>输入为尺寸是(batch_size, 64, 512, 512)的张量<br>
ZeroPad2d(padding = (1, 1, 1, 1), value=0)<br>
-&gt; Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), bias = False)<br>
-&gt;BatchNorm2d<br>
-&gt; ReLU<br>
-&gt;Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias = False)<br>
-&gt; BatchNorm2d<br>
-&gt;ReLU<br>
-&gt;Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), paddding=(1, 1), bias = Fasle)<br>
-&gt; BatchNorm2d<br>
-&gt; ReLU<br>
-&gt; Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias = False)<br>
-&gt; BatchNorm2d<br>
-&gt; ReLU<br>
输出的尺寸为(batch_size, 64, 256, 256)</p>
<h4 id="deblock1">DeBlock1</h4>
<p>输入是Block1的输出<br>
Conv2d(64, 128, kernel_size=(2, 2), stride=(2, 2), bias=False)<br>
-&gt; BatchNorm2d<br>
-&gt; ReLU<br>
输出的尺寸为(batch_size, 128, 128, 128)</p>
<h4 id="block2">Block2</h4>
<p>输入是Block1的输出<br>
ZeroPad2d(padding = (1, 1, 1, 1), value=0)<br>
-&gt; Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), bias = False)<br>
-&gt;BatchNorm2d<br>
-&gt; ReLU<br>
-&gt;Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias = False)<br>
-&gt; BatchNorm2d<br>
-&gt;ReLU<br>
-&gt;Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), paddding=(1, 1), bias = Fasle)<br>
-&gt; BatchNorm2d<br>
-&gt; ReLU<br>
-&gt; Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias = False)<br>
-&gt; BatchNorm2d<br>
-&gt; ReLU<br>
-&gt; Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias = False)<br>
-&gt; BatchNorm2d<br>
-&gt; ReLU<br>
-&gt; Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias = False)<br>
-&gt; BatchNorm2d<br>
-&gt; ReLU<br>
输出的尺寸为(batch_size, 128, 128, 128)</p>
<h4 id="deblock2">DeBlock2</h4>
<p>输入是Block2的输出<br>
Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)<br>
-&gt; BatchNorm2d<br>
-&gt;ReLU<br>
输出的尺寸为(batch_size, 128, 128)</p>
<h4 id="block3">Block3</h4>
<p>输入是Block2的输出<br>
ZeroPad2d(padding = (1, 1, 1, 1), value=0)<br>
-&gt; Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), bias = False)<br>
-&gt;BatchNorm2d<br>
-&gt; ReLU<br>
-&gt;Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias = False)<br>
-&gt; BatchNorm2d<br>
-&gt;ReLU<br>
-&gt;Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), paddding=(1, 1), bias = Fasle)<br>
-&gt; BatchNorm2d<br>
-&gt; ReLU<br>
-&gt; Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias = False)<br>
-&gt; BatchNorm2d<br>
-&gt; ReLU<br>
-&gt; Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias = False)<br>
-&gt; BatchNorm2d<br>
-&gt; ReLU<br>
-&gt; Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias = False)<br>
-&gt; BatchNorm2d<br>
-&gt; ReLU<br>
输出的尺寸为(batch_size, 256, 64, 64)</p>
<h4 id="deblock3">DeBlock3</h4>
<p>输入是Block3的输出<br>
ConvTranspose2d(256, 128, kernel_size=(2, 2), stride = (2, 2), bias = False)<br>
-&gt; BatchNorm2d<br>
-&gt; ReLU</p>
<p>输出的尺寸是(batch_size, 128, 128, 128)</p>
<p><mark style="background: #ff6666">最后RPN的输出, 是将DeBlock1, DeBlock2, DeBlock3的输出进行拼接, 尺寸为(batch_size, 384, 128, 128)</mark></p>
<h3 id="centerhead">CenterHead</h3>
<p>输入为RPN的输出, 尺寸为(batch_size, 384, 128, 128)<br>
先经过Conv2d(384, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))<br>
-&gt; BatchNorm2d<br>
-&gt; ReLU<br>
来提取特征, 输出的尺寸为(batch_size, 64, 128, 128)</p>
<p>对于上面的输出特征, 送入检测头中. 对于每个类别都有下面这些检测头<br>
<mark style="background: #2ea8e5">'reg’检测头(heatmap中心到物体中心点的距离):</mark><br>
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))<br>
-&gt; BatchNorm2d<br>
-&gt; ReLU<br>
-&gt; Conv2d(64, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))</p>
<p><mark style="background: #2ea8e5">'height’检测头:</mark><br>
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))<br>
-&gt; BatchNorm2d<br>
-&gt; ReLU<br>
-&gt; Conv2d(64, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))</p>
<p><mark style="background: #2ea8e5">'dim’检测头:</mark><br>
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))<br>
-&gt; BatchNorm2d<br>
-&gt; ReLU<br>
-&gt; Conv2d(64, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))</p>
<p><mark style="background: #2ea8e5">'rot’检测头:</mark><br>
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))<br>
-&gt; BatchNorm2d<br>
-&gt; ReLU<br>
-&gt; Conv2d(64, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))</p>
<p><mark style="background: #2ea8e5">'vel’检测头:</mark><br>
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))<br>
-&gt; BatchNorm2d<br>
-&gt; ReLU<br>
-&gt; Conv2d(64, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))</p>
<p><mark style="background: #2ea8e5">'hm’检测头(heatmap):</mark><br>
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))<br>
-&gt; BatchNorm2d<br>
-&gt; ReLU<br>
-&gt; Conv2d(64, 类别个数, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))</p>
<p>最后hm检测头是类别个数, 是因为nuscenes数据集将小类别汇成了一些大类<br>
划分如下:<br>
[‘car’]<br>
[‘truck’, ‘construction_vehicle’]<br>
[‘bus’, ‘trailer’]<br>
[‘barrier’]<br>
[‘motorcycle’, ‘bicycle’]<br>
[‘pedestrian’, ‘traffic_cone’]<br>
最后的返回值是一个长度为6的列表, 列表中的每个元素是一个字典, 字典中的键值对: key为回归的检测头的名字, value是这个检测头的输出值</p>
<h2 id="导出rpn部分的模型">导出RPN部分的模型</h2>
<p>代码如下</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">rpn_input  = torch.zeros((<span class="number">1</span>,<span class="number">64</span>,<span class="number">512</span>,<span class="number">512</span>),dtype=torch.float32,device=gpu_device)</span><br><span class="line">torch.onnx.export(pp_model, rpn_input,<span class="string">&quot;onnx_model/rpn.onnx&quot;</span>,opset_version=<span class="number">11</span>)</span><br></pre></td></tr></table></figure>
<p>先创建一个输入张量, 然后送入<code>pp_model</code>里面<br>
其中<code>pp_model</code>包含RPN和CenterHead</p>
<h1 id="简化模型">简化模型</h1>
<h2 id="onnx-simplifier介绍">onnx-simplifier介绍</h2>
<p>代码中使用的是onnx-simplifier进行优化<br>
onnxsim本身只提供了constant folding/propagation的能力, 图变换的能力(合并conv和bn)是由onnx调用onnx optimizer来实现的</p>
<p>constant folding的例子:</p>
<ul>
<li>add(add(x, 1), 2)在变换为add(x, add(1, 2))后可以变成add(x, 3)</li>
<li>pad(conv(x, w, padding=0), add(1, 1))可以变成pad(conv(x, w, padding=0), 2), 可以进一步融合成conv(x, w, padding=2)</li>
</ul>
<p>onnxsim中的<code>simplify</code>函数接收一个输入, 就是模型的地址, 有两个输出, 第一个是简化后的模型, 第二个是<code>check</code>, 用来标记简化是否成功, 如果成功则为True, 否则为False</p>
<h2 id="计算图简化代码">计算图简化代码</h2>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">model = onnx.load(pfe_model_path)</span><br><span class="line">init_dict = &#123;&#125;</span><br><span class="line"><span class="keyword">for</span> init_node <span class="keyword">in</span> model.graph.initializer:</span><br><span class="line">	init_dict[init_node.name] = init_node</span><br></pre></td></tr></table></figure>
<p>上面的代码加载简化后的PFE模型, 然后构建一个字典, 将每个节点的名称和节点对应起来. <code>model.graph.initializer</code>属性存储了模型中所有的初始化参数, 这些参数通常是在训练过程中学习到的, 并在推理阶段保持不变. 常见的例子包括卷积层的滤波器权重, 全连接层的权重和偏置</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">delete_dict = &#123;&#125;</span><br><span class="line"><span class="keyword">for</span> node <span class="keyword">in</span> model.graph.node:</span><br><span class="line">	<span class="keyword">if</span> node.op_type <span class="keyword">in</span> &#123;<span class="string">&quot;Transpose&quot;</span>, <span class="string">&quot;Expand&quot;</span>, <span class="string">&quot;Squeeze&quot;</span>&#125;:</span><br><span class="line">		delete_dict[node.output[<span class="number">0</span>]] = node</span><br></pre></td></tr></table></figure>
<p>如果这个节点的操作是Transpose, Expand, Squeeze, 构建一个字典, 将输出和输入进行对应. <code>model.graph.node</code>包含了计算图中的所有节点, 每个节点定义了操作的类型, 输入和输出张量, 以及相关的属性. <code>node.output</code>是输出张量的名称列表</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">val_len = <span class="built_in">len</span>(model.graph.value_info)</span><br><span class="line"><span class="keyword">for</span> idx <span class="keyword">in</span> <span class="built_in">range</span>(val_len):</span><br><span class="line">	model.graph.value_info.pop()</span><br></pre></td></tr></table></figure>
<p><code>model.graph.value_info</code>包含了计算图中的中间张量. 中间张量表示在计算过程中, 既不是输入张量也不是输出张量的张量. 上面代码的目的是清空所有的中间张量</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">delete_init(model)</span><br><span class="line"><span class="keyword">def</span> <span class="title function_">delete_init</span>(<span class="params">model</span>):</span><br><span class="line">    init_len = <span class="built_in">len</span>(model.graph.initializer)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(init_len):</span><br><span class="line">        model.graph.initializer.pop()</span><br></pre></td></tr></table></figure>
<p>上面代码的目的是清空所有的初始化张量</p>
<h2 id="算子简化">算子简化</h2>
<h3 id="模型输入变化">模型输入变化</h3>
<p>首先在之前说过, 模型的输入的尺寸是(非空voxel个数, 每个voxel中的最大点数, 10)<br>
模型的PFE部分使用的都是全连接层, 想将其转化为卷积层, 因此需要对模型的输入进行一些变化</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">convert_input_nhwc_nchw</span>(<span class="params">model</span>):</span><br><span class="line">    batch_dim = <span class="number">1</span></span><br><span class="line">    dim_list = [dim_val.dim_value <span class="keyword">for</span> dim_val <span class="keyword">in</span> model.graph.<span class="built_in">input</span>[<span class="number">0</span>].<span class="built_in">type</span>.tensor_type.shape.dim]</span><br><span class="line">    dim_list.insert(<span class="number">0</span>, batch_dim)</span><br><span class="line">    dim_list = np.array(dim_list)[[<span class="number">0</span>,<span class="number">3</span>,<span class="number">1</span>,<span class="number">2</span>]]</span><br><span class="line">   </span><br><span class="line">    input_node = onnx.helper.make_tensor_value_info(<span class="string">&#x27;input.1&#x27;</span>, \</span><br><span class="line">                                                    onnx.TensorProto.FLOAT, dim_list.tolist())</span><br><span class="line">    model.graph.<span class="built_in">input</span>.pop()</span><br><span class="line">    model.graph.<span class="built_in">input</span>.append(input_node)</span><br><span class="line">    </span><br><span class="line">    dim_list = [dim_val.dim_value <span class="keyword">for</span> dim_val <span class="keyword">in</span> model.graph.output[<span class="number">0</span>].<span class="built_in">type</span>.tensor_type.shape.dim]</span><br><span class="line">    dim_list.insert(<span class="number">0</span>, batch_dim)</span><br><span class="line">    dim_list.insert(<span class="number">2</span>, <span class="number">1</span>)</span><br><span class="line">    dim_list = np.array(dim_list)[[<span class="number">0</span>,<span class="number">3</span>,<span class="number">1</span>,<span class="number">2</span>]]</span><br><span class="line">   </span><br><span class="line">    out_node = onnx.helper.make_tensor_value_info(model.graph.output[<span class="number">0</span>].name, \</span><br><span class="line">                                                  onnx.TensorProto.FLOAT, dim_list.tolist())</span><br><span class="line">    model.graph.output.pop()</span><br><span class="line">    model.graph.output.append(out_node)</span><br></pre></td></tr></table></figure>
<p>上面的代码主要是将输入的尺寸从(非空voxel个数, 每个voxel中的最大点数, 10)转化为(1, 10, 非空voxel个数, 每个voxel中的最大点数)<br>
其中<code>onnx.helper.make_tensor_value_info</code>是构建一个张量的信息, 第一个输入参数是张量的名字, 第二个输入参数是张量的类型, 第三个输入参数是张量的尺寸<br>
除了转化输入的尺寸外, 还转化了输出的尺寸, 将尺寸从(非空voxel个数, 64)转化为(1, 64, 非空voxel个数, 1)</p>
<h2 id="将全连接层转化为卷积层">将全连接层转化为卷积层</h2>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> node.op_type == <span class="string">&quot;MatMul&quot;</span>:</span><br><span class="line">	node.op_type = <span class="string">&quot;Conv&quot;</span></span><br><span class="line">	matmul_to_conv2d(node, init_dict)</span><br><span class="line"><span class="comment"># matmul_to_conv2d函数定义</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">matmul_to_conv2d</span>(<span class="params">node, init_dict</span>):</span><br><span class="line">    weight_name = node.<span class="built_in">input</span>[<span class="number">1</span>]</span><br><span class="line">    weight_tensor = init_dict[weight_name]</span><br><span class="line">    weight = numpy_helper.to_array(weight_tensor)</span><br><span class="line">    weight = np.expand_dims(weight.transpose(<span class="number">1</span>,<span class="number">0</span>),[<span class="number">2</span>,<span class="number">3</span>])</span><br><span class="line">    weight_tensor = numpy_helper.from_array(weight, name=weight_name)</span><br><span class="line">    init_dict[weight_name] = weight_tensor</span><br></pre></td></tr></table></figure>
<ol>
<li>首先获取权重的名字, <code>node.input[0]</code>一般是输入的张量, <code>node.input[1]</code>一般是权重.</li>
<li>然后通过<code>init_dict</code>获取记录的权重, 这个类型是<code>onnx.onnx_ml_pb2.TensorProto</code></li>
<li>使用<code>onnx.numpy_helper.to_array</code>将权重转化为<code>np.array</code></li>
<li>全连接层记录的权重的尺寸为(输入通道数, 输出通道数). 而卷积层要求的尺寸为(输出通道数, 输入通道数, 卷积核高度, 卷积核宽度), 而全连接层可以和<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1</mn><mo>×</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">1\times1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.72777em;vertical-align:-0.08333em;"></span><span class="mord">1</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">1</span></span></span></span>卷积相互转换, 因此需要进行转置再增添两个维度</li>
<li>最后更新<code>init_dict</code>中的权重</li>
</ol>
<h2 id="删除一些不必要的层">删除一些不必要的层</h2>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> node.<span class="built_in">input</span>[<span class="number">0</span>] <span class="keyword">in</span> delete_dict.keys():</span><br><span class="line">	node.<span class="built_in">input</span>[<span class="number">0</span>] = delete_dict[node.<span class="built_in">input</span>[<span class="number">0</span>]].<span class="built_in">input</span>[<span class="number">0</span>]</span><br></pre></td></tr></table></figure>
<p>在实际的代码过程中, <code>nn.Linear()</code>的输出是(N, L, C)的, 其中C是通道数, 而<code>nn.BatchNorm1d</code>的输入是(N, C, L)的, 因此在<code>nn.BatchNorm1d</code>前后都需要进行转置<br>
但是如果将全连接层改成了卷积操作, 这些转置层就可以优化掉, 而转置操作就在<code>delele_dict</code>里面<br>
上面的操作就是将当前层的输入, 变成<code>Transpose</code>, <code>Squeeze</code>, <code>Expand</code>这些层的输入, 后面会讲到<code>Transpose</code>和<code>Expand</code>为什么要删除, 模型的最后有个<code>Squeeze</code>, 作者也将其删除了</p>
<h2 id="将reducemax转化为maxpooling">将ReduceMax转化为Maxpooling</h2>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> node.op_type == <span class="string">&quot;ReduceMax&quot;</span>:</span><br><span class="line">	rm_list.append(node)</span><br><span class="line">	reducemax_to_maxpool(node, model)</span><br><span class="line"><span class="comment"># reducemax_to_maxpool代码</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">reducemax_to_maxpool</span>(<span class="params">node, model</span>):</span><br><span class="line">    node = helper.make_node(op_type=<span class="string">&quot;MaxPool&quot;</span>, inputs=node.<span class="built_in">input</span>, \</span><br><span class="line">                            outputs=node.output, name=node.name,  \</span><br><span class="line">                            ceil_mode = <span class="number">0</span>, kernel_shape = [<span class="number">1</span>,<span class="number">20</span>], \</span><br><span class="line">                            pads = [<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>], strides=[<span class="number">1</span>,<span class="number">1</span>])</span><br><span class="line">    model.graph.node.append(node)</span><br></pre></td></tr></table></figure>
<p>在原来的模型里面使用的是<code>torch.max</code>, 类型是&quot;ReduceMax&quot;<br>
需要将其转成MaxPooling来提速<br>
<code>helper.make_node</code>用来创建计算节点, 其中<code>ceil_mode</code>表示所有的取整操作采用向下取整</p>
<h2 id="将torch-repeat转化为tile">将torch.repeat转化为Tile</h2>
<p>在pytorch代码中有以下代码</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">x_repeat = x_max.repeat(<span class="number">1</span>, inputs.shape[<span class="number">1</span>], <span class="number">1</span>)</span><br></pre></td></tr></table></figure>
<p>这个代码在onnx中会分解成两步, 一步是<code>Expand</code>, 另外一步是<code>Tile</code><br>
其中<code>Expand</code>操作就是将张量按照广播的原则拓展成对应的尺寸<br>
<code>Tile</code>操作是将张量的不同维度重复对应的次数<br>
根据pytorch的代码, <code>Expand</code>的操作是执行(1, 1, 1), <code>Tile</code>的操作是执行(1, 20, 1)<br>
可以将<code>Expand</code>操作去掉, 去掉<code>Expand</code>操作是在<a href="#%E5%88%A0%E9%99%A4%E4%B8%80%E4%BA%9B%E4%B8%8D%E5%BF%85%E8%A6%81%E7%9A%84%E5%B1%82">删除一些不必要的层</a>中实现的<br>
因为将前面的操作都转化为了二维特征图的形式(N, C, 非空Voxel个数, 1)<br>
因此需要将<code>Tile</code>的参数变为(1, 1, 1, 20)<br>
参考下面的代码</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">convert_tile</span>(<span class="params">node, init_dict</span>):</span><br><span class="line">    arr_name = node.<span class="built_in">input</span>[<span class="number">1</span>]</span><br><span class="line">    arr = np.array([<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">20</span>],np.int64)</span><br><span class="line">    tensor = numpy_helper.from_array(arr, name=arr_name)</span><br><span class="line">    init_dict[arr_name] = tensor</span><br></pre></td></tr></table></figure>
<h2 id="修改拼接的维度">修改拼接的维度</h2>
<p>因为都变成了二维特征图, 因此需要修改拼接的维度</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> node.op_type == <span class="string">&quot;Concat&quot;</span>:</span><br><span class="line">	node.attribute[<span class="number">0</span>].i = <span class="number">1</span></span><br></pre></td></tr></table></figure>
<p>将拼接的维度修改为第一维</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> name,tensor <span class="keyword">in</span> init_dict.items():</span><br><span class="line">	model.graph.initializer.append(tensor)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> keys,node <span class="keyword">in</span> delete_dict.items():</span><br><span class="line">	model.graph.node.remove(node)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> node <span class="keyword">in</span> rm_list:</span><br><span class="line">	model.graph.node.remove(node)</span><br><span class="line"></span><br><span class="line">onnx.save(model, pfe_model_save_path)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Done&quot;</span>)</span><br></pre></td></tr></table></figure>
<p>之前将<code>model.graph.initializer</code>中的张量全部删除了, 现在都加上去, 然后删除之前替换掉的节点</p>
<p><mark style="background: #ff6666">这边的简化包括两部分, 一部分是用onnxsim进行了常量折叠, 另一部分是对模型的一些模块(全连接层, torch.max, torch.repeat)进行了替换(只针对PFE做了替换)</mark></p>
<p>最后, PFE模型的输出会变成(batch_size, 64, 非空voxel个数, 1)</p>
<h1 id="合并pfe和rpn">合并PFE和RPN</h1>
<p>新建了一个<code>ScatterND</code>节点来连接PFE和RPN, 这个节点的作用等同于<a href="#%E6%B2%A1%E6%9C%89%E5%AF%BC%E5%87%BA%E7%9A%84%E9%83%A8%E5%88%86pointpillarsscatter%E4%BB%8B%E7%BB%8D">pointpillarsscatter</a></p>
<h2 id="合并计算图">合并计算图</h2>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">pfe_sim_model_path = <span class="string">&quot;./onnx_model/pfe_sim.onnx&quot;</span></span><br><span class="line">rpn_sim_model_path = <span class="string">&quot;./onnx_model/rpn.onnx&quot;</span></span><br><span class="line">pointpillars_save_path = <span class="string">&quot;./onnx_model/pointpillars.onnx&quot;</span></span><br><span class="line">pointpillars_trt_save_path = <span class="string">&quot;./onnx_model/pointpillars_trt.onnx&quot;</span></span><br><span class="line"></span><br><span class="line">pfe_model = onnx.load(pfe_sim_model_path)</span><br><span class="line">rpn_model = onnx.load(rpn_sim_model_path)</span><br><span class="line"></span><br><span class="line">batch_size = <span class="number">1</span></span><br><span class="line">rpn_input_conv_name = <span class="string">&quot;Conv_15&quot;</span></span><br><span class="line">pfe_out_maxpool_name = <span class="string">&quot;46&quot;</span></span><br><span class="line">rpn_input_shape = [batch_size,<span class="number">64</span>,<span class="number">512</span>,<span class="number">512</span>]</span><br><span class="line">indices_shape = [batch_size, <span class="number">30000</span>,<span class="number">2</span>]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> node <span class="keyword">in</span> pfe_model.graph.node:</span><br><span class="line">	node.name = <span class="string">&quot;pfe_&quot;</span>+node.name</span><br><span class="line"></span><br><span class="line"><span class="comment"># merge nodes, outputs and initializers</span></span><br><span class="line">pfe_model.graph.node.extend(rpn_model.graph.node)</span><br><span class="line">pfe_model.graph.output.pop()</span><br><span class="line">pfe_model.graph.output.extend(rpn_model.graph.output)</span><br><span class="line">pfe_model.graph.initializer.extend(rpn_model.graph.initializer)</span><br><span class="line"></span><br><span class="line">pfe_model_trt = copy.deepcopy(pfe_model)</span><br></pre></td></tr></table></figure>
<p>上面的代码主要做了几件事:</p>
<ol>
<li>加载模型</li>
<li>设置索引的尺寸, 这里设置的是<code>indices_shape = [batch_size, 30000,2]</code>, 也就是非空voxel的个数最大为30000</li>
<li>将PFE模块的名字都加上前缀pfe_</li>
<li>将pfe整个模块的输出设置为rpn_model的输出, 将PFE和RPN模块进行合并(合并节点和里面的参数)</li>
</ol>
<h2 id="构建scatternd来连接pfe和rpn">构建ScatterND来连接PFE和RPN</h2>
<p>上面说了PFE的输出尺寸为(batch_size, 64, 非空voxel个数, 1)<br>
RPN的输入尺寸是(batch_size, 64, 512, 512)<br>
构建ScatterND的代码如下</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br></pre></td><td class="code"><pre><span class="line">make_scatterND(pfe_model, rpn_input_shape, indices_shape, pfe_out_maxpool_name, batch_size)</span><br><span class="line">make_scatterND(pfe_model_trt, rpn_input_shape, indices_shape, pfe_out_maxpool_name, batch_size, save_for_trt=<span class="literal">True</span>)</span><br><span class="line"><span class="comment"># make_scatterND定义</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">make_scatterND</span>(<span class="params">model, rpn_input_shape, indices_shape, pfe_out_maxpool_name, batch_size, save_for_trt=<span class="literal">False</span></span>):</span><br><span class="line">    output_shape = [batch_size, rpn_input_shape[<span class="number">2</span>]*rpn_input_shape[<span class="number">3</span>], rpn_input_shape[<span class="number">1</span>]]</span><br><span class="line">    </span><br><span class="line">    squeeze_node = helper.make_node(op_type=<span class="string">&quot;Squeeze&quot;</span>, inputs=[pfe_out_maxpool_name], \</span><br><span class="line">                                    outputs=[<span class="string">&#x27;pfe_squeeze_1&#x27;</span>], name=<span class="string">&quot;pfe_Squeeze_1&quot;</span>, \</span><br><span class="line">                                    axes = [<span class="number">3</span>])</span><br><span class="line">    </span><br><span class="line">    transpose_node_1 = helper.make_node(op_type=<span class="string">&quot;Transpose&quot;</span>, inputs=[<span class="string">&#x27;pfe_squeeze_1&#x27;</span>,], \</span><br><span class="line">                                        outputs=[<span class="string">&#x27;pfe_transpose_1&#x27;</span>], name=<span class="string">&quot;pfe_Transpose_1&quot;</span>, \</span><br><span class="line">                                        perm=[<span class="number">0</span>,<span class="number">2</span>,<span class="number">1</span>])</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">if</span> save_for_trt:</span><br><span class="line">        scatter_node = helper.make_node(op_type=<span class="string">&quot;ScatterND&quot;</span>, inputs=[<span class="string">&#x27;scatter_data&#x27;</span>, <span class="string">&#x27;indices_input&#x27;</span>, <span class="string">&#x27;pfe_transpose_1&#x27;</span>], \</span><br><span class="line">                                        outputs=[<span class="string">&#x27;scatter_1&#x27;</span>], name=<span class="string">&quot;ScatterND_1&quot;</span>, output_shape=output_shape, index_shape=indices_shape)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        scatter_node = helper.make_node(op_type=<span class="string">&quot;ScatterND&quot;</span>, inputs=[<span class="string">&#x27;scatter_data&#x27;</span>, <span class="string">&#x27;indices_input&#x27;</span>, <span class="string">&#x27;pfe_transpose_1&#x27;</span>], \</span><br><span class="line">                                        outputs=[<span class="string">&#x27;scatter_1&#x27;</span>], name=<span class="string">&quot;ScatterND_1&quot;</span>)</span><br><span class="line"></span><br><span class="line">    transpose_node_2 = helper.make_node(op_type=<span class="string">&quot;Transpose&quot;</span>, inputs=[<span class="string">&#x27;scatter_1&#x27;</span>,], \</span><br><span class="line">                                        outputs=[<span class="string">&#x27;pfe_transpose_2&#x27;</span>], \</span><br><span class="line">                                        name=<span class="string">&quot;pfe_Transpose_2&quot;</span>, perm=[<span class="number">0</span>,<span class="number">2</span>,<span class="number">1</span>])</span><br><span class="line">    reshape_node = helper.make_node(op_type=<span class="string">&quot;Reshape&quot;</span>, inputs=[<span class="string">&quot;pfe_transpose_2&quot;</span>,<span class="string">&quot;pfe_reshape_shape&quot;</span>], \</span><br><span class="line">                                    outputs=[<span class="string">&#x27;rpn_input&#x27;</span>], name=<span class="string">&quot;pfe_reshape_1&quot;</span>)</span><br><span class="line">    </span><br><span class="line">    squeeze_axes = [<span class="number">3</span>]</span><br><span class="line">    squeeze_tensor = np.array(squeeze_axes, dtype=np.int32)</span><br><span class="line">    squeeze_tensor = numpy_helper.from_array(squeeze_tensor, name=<span class="string">&quot;axes&quot;</span>)</span><br><span class="line">    model.graph.initializer.append(squeeze_tensor)</span><br><span class="line">    </span><br><span class="line">    data_shape = [batch_size, rpn_input_shape[<span class="number">2</span>]*rpn_input_shape[<span class="number">3</span>], rpn_input_shape[<span class="number">1</span>]]</span><br><span class="line">    data = np.zeros(data_shape, dtype=np.float32)</span><br><span class="line">    data_tensor = numpy_helper.from_array(data, name=<span class="string">&quot;scatter_data&quot;</span>)</span><br><span class="line">    model.graph.initializer.append(data_tensor)</span><br><span class="line">    </span><br><span class="line">    reshape_shape = np.array(rpn_input_shape, dtype=np.int64)</span><br><span class="line">    reshape_tensor = numpy_helper.from_array(reshape_shape, name=<span class="string">&quot;pfe_reshape_shape&quot;</span>)</span><br><span class="line">    model.graph.initializer.append(reshape_tensor)    </span><br><span class="line">    </span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> save_for_trt:</span><br><span class="line">        idx_type = onnx.TensorProto.INT32</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        idx_type = onnx.TensorProto.INT64</span><br><span class="line"></span><br><span class="line">    input_node = onnx.helper.make_tensor_value_info(<span class="string">&#x27;indices_input&#x27;</span>, idx_type, indices_shape)</span><br><span class="line">    model.graph.<span class="built_in">input</span>.append(input_node)</span><br><span class="line">    </span><br><span class="line">    model.graph.node.append(squeeze_node)</span><br><span class="line">    model.graph.node.append(transpose_node_1)    </span><br><span class="line">    model.graph.node.append(transpose_node_2)    </span><br><span class="line">    </span><br><span class="line">    model.graph.node.append(scatter_node)</span><br><span class="line">    model.graph.node.append(reshape_node)</span><br></pre></td></tr></table></figure>
<p><code>helper.make_node</code>会指定<code>inputs</code>和<code>outputs</code>和<code>name</code>, 相当于在<code>inputs</code>和<code>outputs</code>之间连了一条有向边, 下面根据执行的顺序而不是代码的顺序进行讲解</p>
<h3 id="squeeze层">Squeeze层</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">squeeze_node = helper.make_node(op_type=<span class="string">&quot;Squeeze&quot;</span>, inputs=[pfe_out_maxpool_name], \</span><br><span class="line">								outputs=[<span class="string">&#x27;pfe_squeeze_1&#x27;</span>], name=<span class="string">&quot;pfe_Squeeze_1&quot;</span>, \</span><br><span class="line">								axes = [<span class="number">3</span>])</span><br></pre></td></tr></table></figure>
<p>上面的代码构建了一个Squeeze层, 将尺寸为(batch_size, 64, 非空voxel个数, 1)的张量压缩为(batch_size, 64, 非空voxel个数)</p>
<h3 id="tranpose1层">Tranpose1层</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">transpose_node_1 = helper.make_node(op_type=<span class="string">&quot;Transpose&quot;</span>, inputs=[<span class="string">&#x27;pfe_squeeze_1&#x27;</span>,], \</span><br><span class="line">									outputs=[<span class="string">&#x27;pfe_transpose_1&#x27;</span>], name=<span class="string">&quot;pfe_Transpose_1&quot;</span>, \</span><br><span class="line">									perm=[<span class="number">0</span>,<span class="number">2</span>,<span class="number">1</span>])</span><br></pre></td></tr></table></figure>
<p>Transpose1层将尺寸为(batch_size, 64, 非空voxel个数)的张量转化为(batch_size, 非空voxel个数, 64)</p>
<h3 id="scatternd层">ScatterND层</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> save_for_trt:</span><br><span class="line">        scatter_node = helper.make_node(op_type=<span class="string">&quot;ScatterND&quot;</span>, inputs=[<span class="string">&#x27;scatter_data&#x27;</span>, <span class="string">&#x27;indices_input&#x27;</span>, <span class="string">&#x27;pfe_transpose_1&#x27;</span>], \</span><br><span class="line">                                        outputs=[<span class="string">&#x27;scatter_1&#x27;</span>], name=<span class="string">&quot;ScatterND_1&quot;</span>, output_shape=output_shape, index_shape=indices_shape)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        scatter_node = helper.make_node(op_type=<span class="string">&quot;ScatterND&quot;</span>, inputs=[<span class="string">&#x27;scatter_data&#x27;</span>, <span class="string">&#x27;indices_input&#x27;</span>, <span class="string">&#x27;pfe_transpose_1&#x27;</span>], \</span><br><span class="line">                                        outputs=[<span class="string">&#x27;scatter_1&#x27;</span>], name=<span class="string">&quot;ScatterND_1&quot;</span>)</span><br></pre></td></tr></table></figure>
<p><code>ScatterND</code>节点主要接收三个输入, 第一个data, 也就是这里的<code>scatter_data</code>, 第二个是indices, 也就是这里的<code>indices_input</code>, 第三个是updates, 也就是这里的<code>pfe_transpose_1</code>, 即<a href="#tranpose1%E5%B1%82">tranpose1层</a>的输出<br>
<code>ScatterND</code>节点进行的操作如下</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">output = np.copy(data)</span><br><span class="line">update_indices = indices.shape[:-<span class="number">1</span>]</span><br><span class="line"><span class="keyword">for</span> idx <span class="keyword">in</span> np.ndindex(update_indices):</span><br><span class="line">    output[indices[idx]] = updates[idx]</span><br></pre></td></tr></table></figure>
<p>输出的尺寸和<code>scatter_data</code>的尺寸一致<br>
<code>scatter_data</code>的定义如下, 尺寸为(batch_size, 512*512, 64)</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">data_shape = [batch_size, rpn_input_shape[<span class="number">2</span>]*rpn_input_shape[<span class="number">3</span>], rpn_input_shape[<span class="number">1</span>]]</span><br><span class="line">data = np.zeros(data_shape, dtype=np.float32)</span><br><span class="line">data_tensor = numpy_helper.from_array(data, name=<span class="string">&quot;scatter_data&quot;</span>)</span><br><span class="line">model.graph.initializer.append(data_tensor)</span><br></pre></td></tr></table></figure>
<p>因为TensorRT不支持优化<code>ScatterND</code>操作, 所有需要指定输出尺寸和索引的尺寸</p>
<h3 id="transpose2层">Transpose2层</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">transpose_node_2 = helper.make_node(op_type=<span class="string">&quot;Transpose&quot;</span>, inputs=[<span class="string">&#x27;scatter_1&#x27;</span>,], \</span><br><span class="line">                                        outputs=[<span class="string">&#x27;pfe_transpose_2&#x27;</span>], \</span><br><span class="line">                                        name=<span class="string">&quot;pfe_Transpose_2&quot;</span>, perm=[<span class="number">0</span>,<span class="number">2</span>,<span class="number">1</span>])</span><br></pre></td></tr></table></figure>
<p>Transpose2层将尺寸为(batch_size, 512*512, 64)的张量转化为(batch_size, 64, 512*512)</p>
<h3 id="reshape层">Reshape层</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">reshape_shape = np.array(rpn_input_shape, dtype=np.int64)</span><br><span class="line">reshape_tensor = numpy_helper.from_array(reshape_shape, name=<span class="string">&quot;pfe_reshape_shape&quot;</span>)</span><br><span class="line">model.graph.initializer.append(reshape_tensor)    </span><br></pre></td></tr></table></figure>
<p>主要的操作是将尺寸为(batch_size, 64, 512*512)的张量转化为(batch_size, 64, 512, 512)</p>
<h3 id="额外的输入">额外的输入</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> save_for_trt:</span><br><span class="line">	idx_type = onnx.TensorProto.INT32</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">	idx_type = onnx.TensorProto.INT64</span><br><span class="line"></span><br><span class="line">input_node = onnx.helper.make_tensor_value_info(<span class="string">&#x27;indices_input&#x27;</span>, idx_type, indices_shape)</span><br><span class="line">model.graph.<span class="built_in">input</span>.append(input_node)</span><br></pre></td></tr></table></figure>
<p>如果使用TensorRT, 数据类型是INT32, 否则是INT64<br>
因为模型的输入需要获得voxel的索引, 所以需要加入一个<code>indices_input</code>输入</p>
<h3 id="节点加入计算图">节点加入计算图</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">model.graph.node.append(squeeze_node)</span><br><span class="line">model.graph.node.append(transpose_node_1)    </span><br><span class="line">model.graph.node.append(transpose_node_2)    </span><br><span class="line"></span><br><span class="line">model.graph.node.append(scatter_node)</span><br><span class="line">model.graph.node.append(reshape_node)</span><br></pre></td></tr></table></figure>
<p>节点加入计算图</p>
<h2 id="更改输入的尺寸并存储模型">更改输入的尺寸并存储模型</h2>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">change_input</span>(<span class="params">model</span>):</span><br><span class="line">	<span class="keyword">for</span> node <span class="keyword">in</span> model.graph.node:</span><br><span class="line">		<span class="keyword">if</span> node.name == rpn_input_conv_name:</span><br><span class="line">			node.<span class="built_in">input</span>[<span class="number">0</span>] = <span class="string">&quot;rpn_input&quot;</span></span><br><span class="line">			<span class="keyword">break</span></span><br><span class="line"></span><br><span class="line">		model.graph.<span class="built_in">input</span>[<span class="number">0</span>].<span class="built_in">type</span>.tensor_type.shape.dim[<span class="number">2</span>].dim_value = indices_shape[<span class="number">1</span>]</span><br><span class="line"></span><br><span class="line">change_input(pfe_model)</span><br><span class="line">change_input(pfe_model_trt)</span><br><span class="line"></span><br><span class="line">onnx.save(pfe_model, pointpillars_save_path)</span><br><span class="line">onnx.save(pfe_model_trt, pointpillars_trt_save_path)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Done&quot;</span>)</span><br></pre></td></tr></table></figure>
<p>因为设置了最大非空voxel个数为30000, 因此RPN之前的输入维度都进行了调整, 改成了30000</p>
<h1 id="使用tensorrt进行加速">使用TensorRT进行加速</h1>
<h2 id="下载tensorrt">下载TensorRT</h2>
<p>下载<a target="_blank" rel="noopener" href="https://developer.nvidia.com/nvidia-tensorrt-7x-download?form=submitted">TensorRT7.2.1.6</a><br>
<img src="https://raw.githubusercontent.com/zhangtingyu11/PictureBed/main/202405152211456.png" alt=""></p>
<p>下载完之后进行解压</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tar -xzvf TensorRT-7.2.1.6.Ubuntu-18.04.x86_64-gnu.cuda-11.1.cudnn8.0.tar.gz</span><br></pre></td></tr></table></figure>
<h2 id="获取点云数据">获取点云数据</h2>
<p>运行CenterPoint下面的TensorRT_Visualize.ipynb, 点云数据会存放在<code>CenterPoint/tensorrt</code>下面,<br>
中间如果出现<code>module 'numpy' has no attribute 'float'.</code>也没有问题, 不会影响数据生成</p>
<h2 id="编译tensorrt">编译TensorRT</h2>
<p>将<code>CenterPoint/tensorrt/sample</code> 和 <code>CenterPoint/tensorrt/data</code> 放入 <code>TensorRT-7.2.1.6</code>文件夹下(需要合并), 然后按照下面的指令将头文件和库文件放入系统头文件和库文件中</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 在TensorRT-7.2.1.6文件夹下</span></span><br><span class="line">sudo <span class="built_in">cp</span> -r ./lib/* /usr/lib</span><br><span class="line">sudo <span class="built_in">cp</span> -r ./include/* /usr/include</span><br></pre></td></tr></table></figure>
<p><strong>编译</strong></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cd TensorRT-7.2.1.6/samples</span><br><span class="line">make</span><br></pre></td></tr></table></figure>
<h2 id="代码解析">代码解析</h2>
<h3 id="parseargs函数">parseArgs函数</h3>
<p>函数代码如下</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">inline</span> <span class="type">bool</span> <span class="title">parseArgs</span><span class="params">(Args&amp; args, <span class="type">int32_t</span> argc, <span class="type">char</span>* argv[])</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">while</span> (<span class="number">1</span>)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="type">int32_t</span> arg;</span><br><span class="line">        <span class="type">static</span> <span class="keyword">struct</span> <span class="title class_">option</span> long_options[] = &#123;&#123;<span class="string">&quot;help&quot;</span>, no_argument, <span class="number">0</span>, <span class="string">&#x27;h&#x27;</span>&#125;, &#123;<span class="string">&quot;datadir&quot;</span>, required_argument, <span class="number">0</span>, <span class="string">&#x27;d&#x27;</span>&#125;,</span><br><span class="line">            &#123;<span class="string">&quot;int8&quot;</span>, no_argument, <span class="number">0</span>, <span class="string">&#x27;i&#x27;</span>&#125;, &#123;<span class="string">&quot;fp16&quot;</span>, no_argument, <span class="number">0</span>, <span class="string">&#x27;f&#x27;</span>&#125;, &#123;<span class="string">&quot;useILoop&quot;</span>, no_argument, <span class="number">0</span>, <span class="string">&#x27;l&#x27;</span>&#125;,</span><br><span class="line">            &#123;<span class="string">&quot;saveEngine&quot;</span>, required_argument, <span class="number">0</span>, <span class="string">&#x27;s&#x27;</span>&#125;, &#123;<span class="string">&quot;loadEngine&quot;</span>, no_argument, <span class="number">0</span>, <span class="string">&#x27;o&#x27;</span>&#125;,</span><br><span class="line">            &#123;<span class="string">&quot;useDLACore&quot;</span>, required_argument, <span class="number">0</span>, <span class="string">&#x27;u&#x27;</span>&#125;, &#123;<span class="string">&quot;batch&quot;</span>, required_argument, <span class="number">0</span>, <span class="string">&#x27;b&#x27;</span>&#125;, &#123;<span class="literal">nullptr</span>, <span class="number">0</span>, <span class="literal">nullptr</span>, <span class="number">0</span>&#125;&#125;;</span><br><span class="line">        <span class="type">int32_t</span> option_index = <span class="number">0</span>;</span><br><span class="line">        arg = <span class="built_in">getopt_long</span>(argc, argv, <span class="string">&quot;hd:iu&quot;</span>, long_options, &amp;option_index);</span><br><span class="line">        <span class="keyword">if</span> (arg == <span class="number">-1</span>)</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="keyword">break</span>;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">switch</span> (arg)</span><br><span class="line">        &#123;</span><br><span class="line">        <span class="keyword">case</span> <span class="string">&#x27;h&#x27;</span>: args.help = <span class="literal">true</span>; <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">        <span class="keyword">case</span> <span class="string">&#x27;d&#x27;</span>:</span><br><span class="line">            <span class="keyword">if</span> (optarg)</span><br><span class="line">            &#123;</span><br><span class="line">                args.dataDirs.<span class="built_in">push_back</span>(optarg);</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">else</span></span><br><span class="line">            &#123;</span><br><span class="line">                std::cerr &lt;&lt; <span class="string">&quot;ERROR: --datadir requires option argument&quot;</span> &lt;&lt; std::endl;</span><br><span class="line">                <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">break</span>;</span><br><span class="line">        <span class="keyword">case</span> <span class="string">&#x27;s&#x27;</span>:</span><br><span class="line">            <span class="keyword">if</span> (optarg)</span><br><span class="line">            &#123;</span><br><span class="line">                args.saveEngine = optarg;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">break</span>;</span><br><span class="line">        <span class="keyword">case</span> <span class="string">&#x27;o&#x27;</span>:</span><br><span class="line">            <span class="keyword">if</span> (optarg)</span><br><span class="line">            &#123;</span><br><span class="line">                args.loadEngine = optarg;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">break</span>;</span><br><span class="line">        <span class="keyword">case</span> <span class="string">&#x27;i&#x27;</span>: args.runInInt8 = <span class="literal">true</span>; <span class="keyword">break</span>;</span><br><span class="line">        <span class="keyword">case</span> <span class="string">&#x27;f&#x27;</span>: args.runInFp16 = <span class="literal">true</span>; <span class="keyword">break</span>;</span><br><span class="line">        <span class="keyword">case</span> <span class="string">&#x27;l&#x27;</span>: args.useILoop = <span class="literal">true</span>; <span class="keyword">break</span>;</span><br><span class="line">        <span class="keyword">case</span> <span class="string">&#x27;u&#x27;</span>:</span><br><span class="line">            <span class="keyword">if</span> (optarg)</span><br><span class="line">            &#123;</span><br><span class="line">                args.useDLACore = std::<span class="built_in">stoi</span>(optarg);</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">break</span>;</span><br><span class="line">        <span class="keyword">case</span> <span class="string">&#x27;b&#x27;</span>:</span><br><span class="line">            <span class="keyword">if</span> (optarg)</span><br><span class="line">            &#123;</span><br><span class="line">                args.batch = std::<span class="built_in">stoi</span>(optarg);</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">break</span>;</span><br><span class="line">        <span class="keyword">default</span>: <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>这个函数的主要作用是解析命令行<br>
其中<code>struct option</code>包含以下四个属性:</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">struct</span> <span class="title class_">option</span> &#123;</span><br><span class="line">   <span class="type">const</span> <span class="type">char</span> *name;</span><br><span class="line">   <span class="type">int</span>         has_arg;</span><br><span class="line">   <span class="type">int</span>        *flag;</span><br><span class="line">   <span class="type">int</span>         val;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>
<ul>
<li><code>name</code>: 长选项的名字</li>
<li><code>has_arg</code>: 有三种选项
<ul>
<li><code>no_argument=0</code>, 表示这个长参数不带参数, 比如–name</li>
<li><code>required_argument=1</code>表示这个长参数必须带参数, 比如–name Bob</li>
<li><code>optional_argument=2</code>表示这个长参数后面带的参数是可选的, 即–name和–name Bob均可</li>
</ul>
</li>
<li><code>flag</code>: 确定<code>getopt_long</code>这个函数的返回值, 如果<code>flag==NULL</code>, 那么返回值就是结构体的第四个参数<code>val</code>, 否则返回值是0, <code>flag</code>指向一个设置到<code>val</code>的变量</li>
<li><code>val</code>: 参考<code>flag</code>参数</li>
</ul>
<p><strong>注意:</strong> <mark style="background: #ff6666"><code>struct option</code>的最后一个元素必须是全0填充, 否则会报段错误</mark></p>
<p>需要不断的运行<code>getopt_long</code>才能一个一个解析, 如果解析完成, 会返回-1<br>
对于短参数<code>&quot;hd:iu&quot;</code>, 后面不带冒号表示这个参数后面不带指定值, 如果带一个冒号表示这个参数后面带指定值, 如果带两个冒号表示这个参数后面可以带指定值也可以不带</p>
<p>后面的代码就是根据解析到的来进行设置. ==但是其实代码里面根本没用到这些配置==</p>
<h3 id="初始化参数函数initializesampleparams">初始化参数函数initializeSampleParams</h3>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">samplesCommon::OnnxSampleParams <span class="title">initializeSampleParams</span><span class="params">(<span class="type">const</span> samplesCommon::Args&amp; args)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    samplesCommon::OnnxSampleParams params;</span><br><span class="line">    <span class="keyword">if</span> (args.dataDirs.<span class="built_in">empty</span>()) <span class="comment">//!&lt; Use default directories if user hasn&#x27;t provided directory paths</span></span><br><span class="line">    &#123;</span><br><span class="line">        params.dataDirs.<span class="built_in">push_back</span>(<span class="string">&quot;data/centerpoint/&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">else</span> <span class="comment">//!&lt; Use the data directory provided by the user</span></span><br><span class="line">    &#123;</span><br><span class="line">        params.dataDirs = args.dataDirs;</span><br><span class="line">    &#125;</span><br><span class="line">    params.onnxFileName = <span class="string">&quot;pointpillars_trt.onnx&quot;</span>;</span><br><span class="line">    params.inputTensorNames.<span class="built_in">push_back</span>(<span class="string">&quot;input.1&quot;</span>);</span><br><span class="line">    params.inputTensorNames.<span class="built_in">push_back</span>(<span class="string">&quot;indices_input&quot;</span>);</span><br><span class="line"></span><br><span class="line">    params.dlaCore = args.useDLACore;</span><br><span class="line">    params.fp16 = <span class="literal">true</span>;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> params;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><code>params</code>是<code>samplesCommon::OnnxSampleParams</code>结构体, 结构体定义如下</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">struct</span> <span class="title class_">OnnxSampleParams</span> : <span class="keyword">public</span> SampleParams</span><br><span class="line">&#123;</span><br><span class="line">    std::string onnxFileName; <span class="comment">//!&lt; Filename of ONNX file of a network</span></span><br><span class="line">&#125;;</span><br><span class="line"># 其父结构体定义</span><br><span class="line"><span class="keyword">struct</span> <span class="title class_">SampleParams</span></span><br><span class="line">&#123;</span><br><span class="line">    <span class="type">int32_t</span> batchSize&#123;<span class="number">1</span>&#125;;              <span class="comment">//!&lt; Number of inputs in a batch</span></span><br><span class="line">    <span class="type">int32_t</span> dlaCore&#123;<span class="number">-1</span>&#125;;               <span class="comment">//!&lt; Specify the DLA core to run network on.</span></span><br><span class="line">    <span class="type">bool</span> int8&#123;<span class="literal">false</span>&#125;;                  <span class="comment">//!&lt; Allow runnning the network in Int8 mode.</span></span><br><span class="line">    <span class="type">bool</span> fp16&#123;<span class="literal">false</span>&#125;;                  <span class="comment">//!&lt; Allow running the network in FP16 mode.</span></span><br><span class="line">    std::vector&lt;std::string&gt; dataDirs; <span class="comment">//!&lt; Directory paths where sample data files are stored</span></span><br><span class="line">    std::vector&lt;std::string&gt; inputTensorNames;</span><br><span class="line">    std::vector&lt;std::string&gt; outputTensorNames;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>
<p>其中<code>batchSize</code>参数就是模型的batchsize, <code>dlaCore</code>暂时不知道是什么, 也没有用到, <code>int8</code>表示是否允许网络在Int8模式下运行, <code>fp16</code>表示是否允许网络在FP16模式下运行, <code>dataDirs</code>表示样例文件的存储路径, <code>inputTensorNames</code>表示输入张量的名称, <code>outputTensorNames</code>表示输出张量的名称. <code>onnxFileName</code>是onnx文件的名称</p>
<h3 id="build函数">build函数</h3>
<p>因为这个函数比较长, 下面对每个代码片段进行解析</p>
<h4 id="创建builder">创建builder</h4>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">auto</span> builder = <span class="built_in">SampleUniquePtr</span>&lt;nvinfer1::IBuilder&gt;(nvinfer1::<span class="built_in">createInferBuilder</span>(sample::gLogger.<span class="built_in">getTRTLogger</span>()));</span><br><span class="line"><span class="keyword">if</span> (!builder)</span><br><span class="line">&#123;</span><br><span class="line">	<span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>其中<code>sample::gLogger</code>继承自TensorRT中的<code>nvinfer1::ILogger</code>类, <code>sample::gLogger.getTRTLogger()</code>就是返回这个类本身<br>
其中<code>nvinfer1::createInferBuilder</code>的入参是<code>nvinfer1::ILogger</code>类, 创建一个<code>nvinfer1::IBuilder</code>指针</p>
<p><code>SampleUniquePtr</code>定义如下,</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">using</span> SampleUniquePtr = std::unique_ptr&lt;T, samplesCommon::InferDeleter&gt;;</span><br></pre></td></tr></table></figure>
<p>其接收一个模板, 第二个输入<code>samplesCommon::InferDeleter</code>是一个析构器</p>
<h4 id="创建网络">创建网络</h4>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">const</span> <span class="keyword">auto</span> explicitBatch = <span class="number">1U</span> &lt;&lt; <span class="built_in">static_cast</span>&lt;<span class="type">uint32_t</span>&gt;(NetworkDefinitionCreationFlag::kEXPLICIT_BATCH);</span><br></pre></td></tr></table></figure>
<p>上面的语句就是将<code>explicitBatch</code>设置成1</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">auto</span> network = <span class="built_in">SampleUniquePtr</span>&lt;nvinfer1::INetworkDefinition&gt;(builder-&gt;<span class="built_in">createNetworkV2</span>(explicitBatch));</span><br><span class="line"><span class="keyword">if</span> (!network)</span><br><span class="line">&#123;</span><br><span class="line">	<span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>上面的代码, 调用<code>nvinfer1::IBuilder::createNetworkV2</code>来创建一个网络. 这个只是创建网络, 网络内部并没有什么内容, 后序还需要填充网络</p>
<h4 id="创建配置对象">创建配置对象</h4>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">auto</span> config = <span class="built_in">SampleUniquePtr</span>&lt;nvinfer1::IBuilderConfig&gt;(builder-&gt;<span class="built_in">createBuilderConfig</span>());</span><br><span class="line"><span class="keyword">if</span> (!config)</span><br><span class="line">&#123;</span><br><span class="line">	<span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>上面的代码创建了一个builder的配置对象</p>
<h4 id="创建onnx解析器对象">创建onnx解析器对象</h4>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">auto</span> parser</span><br><span class="line">	= <span class="built_in">SampleUniquePtr</span>&lt;nvonnxparser::IParser&gt;(nvonnxparser::<span class="built_in">createParser</span>(*network, sample::gLogger.<span class="built_in">getTRTLogger</span>()));</span><br><span class="line"><span class="keyword">if</span> (!parser)</span><br><span class="line">&#123;</span><br><span class="line">	<span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>上面的代码创建了一个onnx的解析器对象, 输入的参数, 第一个是之前创建的network, 第二个是<code>nvinfer1::ILogger</code>类</p>
<h4 id="填充网络">填充网络</h4>
<p>填充网络的代码主要在<code>constructNetwork</code>函数中</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">bool</span> <span class="title">SampleCenterPoint::constructNetwork</span><span class="params">(SampleUniquePtr&lt;nvinfer1::IBuilder&gt;&amp; builder,</span></span></span><br><span class="line"><span class="params"><span class="function">    SampleUniquePtr&lt;nvinfer1::INetworkDefinition&gt;&amp; network, SampleUniquePtr&lt;nvinfer1::IBuilderConfig&gt;&amp; config,</span></span></span><br><span class="line"><span class="params"><span class="function">    SampleUniquePtr&lt;nvonnxparser::IParser&gt;&amp; parser)</span></span></span><br><span class="line"><span class="function"></span>&#123;   </span><br><span class="line">    <span class="keyword">auto</span> parsed = parser-&gt;<span class="built_in">parseFromFile</span>(<span class="built_in">locateFile</span>(mParams.onnxFileName, mParams.dataDirs).<span class="built_in">c_str</span>(),</span><br><span class="line">        <span class="built_in">static_cast</span>&lt;<span class="type">int</span>&gt;(sample::gLogger.<span class="built_in">getReportableSeverity</span>()));</span><br><span class="line">    <span class="keyword">if</span> (!parsed)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    config-&gt;<span class="built_in">setMaxWorkspaceSize</span>(<span class="number">1</span>_GiB);</span><br><span class="line">    <span class="keyword">if</span> (mParams.fp16)</span><br><span class="line">    &#123;</span><br><span class="line">        config-&gt;<span class="built_in">setFlag</span>(BuilderFlag::kFP16);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    samplesCommon::<span class="built_in">enableDLA</span>(builder.<span class="built_in">get</span>(), config.<span class="built_in">get</span>(), mParams.dlaCore);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><code>locateFile</code>函数如下:</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">inline</span> std::string <span class="title">locateFile</span><span class="params">(<span class="type">const</span> std::string&amp; filepathSuffix, <span class="type">const</span> std::vector&lt;std::string&gt;&amp; directories)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="type">const</span> <span class="type">int</span> MAX_DEPTH&#123;<span class="number">10</span>&#125;;</span><br><span class="line">    <span class="type">bool</span> found&#123;<span class="literal">false</span>&#125;;</span><br><span class="line">    std::string filepath;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">auto</span>&amp; dir : directories)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="keyword">if</span> (!dir.<span class="built_in">empty</span>() &amp;&amp; dir.<span class="built_in">back</span>() != <span class="string">&#x27;/&#x27;</span>)</span><br><span class="line">        &#123;</span><br><span class="line"><span class="meta">#<span class="keyword">ifdef</span> _MSC_VER</span></span><br><span class="line">            filepath = dir + <span class="string">&quot;\\&quot;</span> + filepathSuffix;</span><br><span class="line"><span class="meta">#<span class="keyword">else</span></span></span><br><span class="line">            filepath = dir + <span class="string">&quot;/&quot;</span> + filepathSuffix;</span><br><span class="line"><span class="meta">#<span class="keyword">endif</span></span></span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">else</span></span><br><span class="line">        &#123;</span><br><span class="line">            filepath = dir + filepathSuffix;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; MAX_DEPTH &amp;&amp; !found; i++)</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="function"><span class="type">const</span> std::ifstream <span class="title">checkFile</span><span class="params">(filepath)</span></span>;</span><br><span class="line">            found = checkFile.<span class="built_in">is_open</span>();</span><br><span class="line">            <span class="keyword">if</span> (found)</span><br><span class="line">            &#123;</span><br><span class="line">                <span class="keyword">break</span>;</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            filepath = <span class="string">&quot;../&quot;</span> + filepath; <span class="comment">// Try again in parent dir</span></span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> (found)</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="keyword">break</span>;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        filepath.<span class="built_in">clear</span>();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Could not find the file</span></span><br><span class="line">    <span class="keyword">if</span> (filepath.<span class="built_in">empty</span>())</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="type">const</span> std::string dirList = std::<span class="built_in">accumulate</span>(directories.<span class="built_in">begin</span>() + <span class="number">1</span>, directories.<span class="built_in">end</span>(), directories.<span class="built_in">front</span>(),</span><br><span class="line">            [](<span class="type">const</span> std::string&amp; a, <span class="type">const</span> std::string&amp; b) &#123; <span class="keyword">return</span> a + <span class="string">&quot;\n\t&quot;</span> + b; &#125;);</span><br><span class="line">        std::cout &lt;&lt; <span class="string">&quot;Could not find &quot;</span> &lt;&lt; filepathSuffix &lt;&lt; <span class="string">&quot; in data directories:\n\t&quot;</span> &lt;&lt; dirList &lt;&lt; std::endl;</span><br><span class="line">        std::cout &lt;&lt; <span class="string">&quot;&amp;&amp;&amp;&amp; FAILED&quot;</span> &lt;&lt; std::endl;</span><br><span class="line">        <span class="built_in">exit</span>(EXIT_FAILURE);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> filepath;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>这个函数的主要功能是在目录里面找路径后缀为<code>filepathSuffix</code>的文件, 如果找到了就返回这个路径, 如果没找到就会退出程序<br>
<code>parseFromFile</code>这个函数会解析onnx文件, 第一个参数就是onnx文件的路径, 第二个参数是日志的详细等级</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">config-&gt;<span class="built_in">setMaxWorkspaceSize</span>(<span class="number">1</span>_GiB);</span><br></pre></td></tr></table></figure>
<p>TensorRT在编译的时候会寻找不同的实现方法来判断哪个实现方法更优, 不同的实现方法占用的显存不一样, 上面这个函数就表示搜索的解空间的大小</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> (mParams.fp16)</span><br><span class="line">&#123;</span><br><span class="line">	config-&gt;<span class="built_in">setFlag</span>(BuilderFlag::kFP16);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>如果设置了FP16, 就会设置让模型用FP16的精度来运行</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">samplesCommon::<span class="built_in">enableDLA</span>(builder.<span class="built_in">get</span>(), config.<span class="built_in">get</span>(), mParams.dlaCore);</span><br></pre></td></tr></table></figure>
<p>上面的代码没什么用, 设置里面没有用DLA进行加速</p>
<h4 id="构建engine">构建Engine</h4>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">mEngine = std::<span class="built_in">shared_ptr</span>&lt;nvinfer1::ICudaEngine&gt;(</span><br><span class="line">	builder-&gt;<span class="built_in">buildEngineWithConfig</span>(*network, *config), samplesCommon::<span class="built_in">InferDeleter</span>());</span><br><span class="line"><span class="keyword">if</span> (!mEngine)</span><br><span class="line">&#123;</span><br><span class="line">	<span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>上面的代码用于构建Engine, 虽然后面好像没用到</p>
<h4 id="输入模型输入输出个数等信息">输入模型输入输出个数等信息</h4>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">sample::gLogInfo &lt;&lt; <span class="string">&quot;getNbInputs: &quot;</span> &lt;&lt; network-&gt;<span class="built_in">getNbInputs</span>() &lt;&lt; <span class="string">&quot; \n&quot;</span> &lt;&lt; std::endl;</span><br><span class="line">sample::gLogInfo &lt;&lt; <span class="string">&quot;getNbOutputs: &quot;</span> &lt;&lt; network-&gt;<span class="built_in">getNbOutputs</span>() &lt;&lt; <span class="string">&quot; \n&quot;</span> &lt;&lt; std::endl;</span><br><span class="line">sample::gLogInfo &lt;&lt; <span class="string">&quot;getNbOutputs Name: &quot;</span> &lt;&lt; network-&gt;<span class="built_in">getOutput</span>(<span class="number">0</span>)-&gt;<span class="built_in">getName</span>() &lt;&lt; <span class="string">&quot; \n&quot;</span> &lt;&lt; std::endl;</span><br><span class="line"></span><br><span class="line">mInputDims = network-&gt;<span class="built_in">getInput</span>(<span class="number">0</span>)-&gt;<span class="built_in">getDimensions</span>();</span><br><span class="line"></span><br><span class="line">mOutputDims = network-&gt;<span class="built_in">getOutput</span>(<span class="number">0</span>)-&gt;<span class="built_in">getDimensions</span>();</span><br></pre></td></tr></table></figure>
<p><code>network-&gt;getNbInputs()</code>获取网络的输入数量, <code>network-&gt;getNbOutputs()</code>获取网络的输出数量, <code>network-&gt;getOutput(0)-&gt;getName()</code>获取网络的第一个输出的名字, <code>network-&gt;getInput(0)-&gt;getDimensions()</code>获取网络的第一个输入的维度, <code>network-&gt;getOutput(0)-&gt;getDimensions()</code>获取网络的第一个输出的维度</p>
<h3 id="infer函数">infer函数</h3>
<h4 id="创建内存管理器">创建内存管理器</h4>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">samplesCommon::BufferManager <span class="title">buffers</span><span class="params">(mEngine)</span></span>;</span><br><span class="line"># BufferManager的构造函数如下</span><br><span class="line"><span class="built_in">BufferManager</span>(std::shared_ptr&lt;nvinfer1::ICudaEngine&gt; engine, <span class="type">const</span> <span class="type">int</span> batchSize = <span class="number">0</span>,</span><br><span class="line">        <span class="type">const</span> nvinfer1::IExecutionContext* context = <span class="literal">nullptr</span>)</span><br><span class="line">        : <span class="built_in">mEngine</span>(engine)</span><br><span class="line">        , <span class="built_in">mBatchSize</span>(batchSize)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="comment">// Full Dims implies no batch size.</span></span><br><span class="line">        <span class="built_in">assert</span>(engine-&gt;<span class="built_in">hasImplicitBatchDimension</span>() || mBatchSize == <span class="number">0</span>);</span><br><span class="line">        <span class="comment">// Create host and device buffers</span></span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; mEngine-&gt;<span class="built_in">getNbBindings</span>(); i++)</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="keyword">auto</span> dims = context ? context-&gt;<span class="built_in">getBindingDimensions</span>(i) : mEngine-&gt;<span class="built_in">getBindingDimensions</span>(i);</span><br><span class="line">            <span class="type">size_t</span> vol = context || !mBatchSize ? <span class="number">1</span> : <span class="built_in">static_cast</span>&lt;<span class="type">size_t</span>&gt;(mBatchSize);</span><br><span class="line">            nvinfer1::DataType type = mEngine-&gt;<span class="built_in">getBindingDataType</span>(i);</span><br><span class="line">            <span class="type">int</span> vecDim = mEngine-&gt;<span class="built_in">getBindingVectorizedDim</span>(i);</span><br><span class="line">            <span class="keyword">if</span> (<span class="number">-1</span> != vecDim) <span class="comment">// i.e., 0 != lgScalarsPerVector</span></span><br><span class="line">            &#123;</span><br><span class="line">                <span class="type">int</span> scalarsPerVec = mEngine-&gt;<span class="built_in">getBindingComponentsPerElement</span>(i);</span><br><span class="line">                dims.d[vecDim] = <span class="built_in">divUp</span>(dims.d[vecDim], scalarsPerVec);</span><br><span class="line">                vol *= scalarsPerVec;</span><br><span class="line">            &#125;</span><br><span class="line">            vol *= samplesCommon::<span class="built_in">volume</span>(dims);</span><br><span class="line">            std::unique_ptr&lt;ManagedBuffer&gt; manBuf&#123;<span class="keyword">new</span> <span class="built_in">ManagedBuffer</span>()&#125;;</span><br><span class="line">            manBuf-&gt;deviceBuffer = <span class="built_in">DeviceBuffer</span>(vol, type);</span><br><span class="line">            manBuf-&gt;hostBuffer = <span class="built_in">HostBuffer</span>(vol, type);</span><br><span class="line">            mDeviceBindings.<span class="built_in">emplace_back</span>(manBuf-&gt;deviceBuffer.<span class="built_in">data</span>());</span><br><span class="line">            mManagedBuffers.<span class="built_in">emplace_back</span>(std::<span class="built_in">move</span>(manBuf));</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>
<p>下面进行逐行解释</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; mEngine-&gt;<span class="built_in">getNbBindings</span>(); i++)</span><br></pre></td></tr></table></figure>
<p><code>mEngine-&gt;getNbBindings()</code>是获取网络的输入输出的总数, 也就是这个循环是遍历网络的所有输入输出</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">auto</span> dims = context ? context-&gt;<span class="built_in">getBindingDimensions</span>(i) : mEngine-&gt;<span class="built_in">getBindingDimensions</span>(i);</span><br></pre></td></tr></table></figure>
<p>上面的代码获取第<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>i</mi></mrow><annotation encoding="application/x-tex">i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.65952em;vertical-align:0em;"></span><span class="mord mathdefault">i</span></span></span></span>个输入输出的尺寸, 在这么代码里面<code>context</code>是空的, 所以只会从<code>mEngine</code>中获取</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">size_t</span> vol = context || !mBatchSize ? <span class="number">1</span> : <span class="built_in">static_cast</span>&lt;<span class="type">size_t</span>&gt;(mBatchSize);</span><br></pre></td></tr></table></figure>
<p>在这个代码里, <code>mBatchSize</code>为0, 因此<code>vol</code>被初始化为1</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nvinfer1::DataType type = mEngine-&gt;<span class="built_in">getBindingDataType</span>(i);</span><br></pre></td></tr></table></figure>
<p>上面的代码是获取第<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>i</mi></mrow><annotation encoding="application/x-tex">i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.65952em;vertical-align:0em;"></span><span class="mord mathdefault">i</span></span></span></span>个输入输出的数据类型, 比如是<code>nvinfer1::DataType::kFLOAT</code></p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">int</span> vecDim = mEngine-&gt;<span class="built_in">getBindingVectorizedDim</span>(i);</span><br><span class="line"><span class="keyword">if</span> (<span class="number">-1</span> != vecDim) <span class="comment">// i.e., 0 != lgScalarsPerVector</span></span><br><span class="line">&#123;</span><br><span class="line">	<span class="type">int</span> scalarsPerVec = mEngine-&gt;<span class="built_in">getBindingComponentsPerElement</span>(i);</span><br><span class="line">	dims.d[vecDim] = <span class="built_in">divUp</span>(dims.d[vecDim], scalarsPerVec);</span><br><span class="line">	vol *= scalarsPerVec;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>上面的代码不知道是什么意思, 网上说<code>getBindingVectorizedDim</code>是向量化维度, 但是不知道向量化维度是什么东西, 后面也没用到这个, 因此直接跳过</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">vol *= samplesCommon::<span class="built_in">volume</span>(dims);</span><br><span class="line"># samplesCommon::volume定义如下</span><br><span class="line"><span class="function"><span class="keyword">inline</span> <span class="type">int64_t</span> <span class="title">volume</span><span class="params">(<span class="type">const</span> nvinfer1::Dims&amp; d)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">return</span> std::<span class="built_in">accumulate</span>(d.d, d.d + d.nbDims, <span class="number">1</span>, std::<span class="built_in">multiplies</span>&lt;<span class="type">int64_t</span>&gt;());</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><code>volume</code>函数其实就是将各个维度乘起来, 类似于<code>numel</code>, 然后更新<code>vol</code></p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">std::unique_ptr&lt;ManagedBuffer&gt; manBuf&#123;<span class="keyword">new</span> <span class="built_in">ManagedBuffer</span>()&#125;;</span><br><span class="line"># ManagedBuffer类定义</span><br><span class="line"><span class="keyword">class</span> <span class="title class_">ManagedBuffer</span></span><br><span class="line">&#123;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    DeviceBuffer deviceBuffer;</span><br><span class="line">    HostBuffer hostBuffer;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>
<p>其中<code>DeviceBuffer</code>是管理GPU上的内存, <code>HostBuffer</code>是管理CPU上的内存, 具体的就不展开了</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">manBuf-&gt;deviceBuffer = <span class="built_in">DeviceBuffer</span>(vol, type);</span><br><span class="line">manBuf-&gt;hostBuffer = <span class="built_in">HostBuffer</span>(vol, type);</span><br></pre></td></tr></table></figure>
<p>上面的代码分别分配这个张量的CPU上的内存和GPU上的内存</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mDeviceBindings.<span class="built_in">emplace_back</span>(manBuf-&gt;deviceBuffer.<span class="built_in">data</span>());</span><br></pre></td></tr></table></figure>
<p>上面的代码将这个张量GPU上的数据加入<code>mDeviceBindings</code>中</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mManagedBuffers.<span class="built_in">emplace_back</span>(std::<span class="built_in">move</span>(manBuf));</span><br></pre></td></tr></table></figure>
<p>上面的代码将<code>manBuf</code>加上<code>mManagedBuffers</code>中</p>
<h4 id="创建执行上下文">创建执行上下文</h4>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">auto</span> context = <span class="built_in">SampleUniquePtr</span>&lt;nvinfer1::IExecutionContext&gt;(mEngine-&gt;<span class="built_in">createExecutionContext</span>());</span><br><span class="line"><span class="keyword">if</span> (!context)</span><br><span class="line">&#123;</span><br><span class="line">	<span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>上面的代码创建执行上下文</p>
<h4 id="获取voxel和voxel的索引的内存">获取voxel和voxel的索引的内存</h4>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">float</span>* hostPillars = <span class="built_in">static_cast</span>&lt;<span class="type">float</span>*&gt;(buffers.<span class="built_in">getHostBuffer</span>(mParams.inputTensorNames[<span class="number">0</span>]));</span><br><span class="line"><span class="type">int32_t</span>* hostIndex = <span class="built_in">static_cast</span>&lt;<span class="type">int32_t</span>*&gt;(buffers.<span class="built_in">getHostBuffer</span>(mParams.inputTensorNames[<span class="number">1</span>]));    </span><br></pre></td></tr></table></figure>
<p>先看<code>getHostBuffer</code>函数</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">void</span>* <span class="title">getHostBuffer</span><span class="params">(<span class="type">const</span> std::string&amp; tensorName)</span> <span class="type">const</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">	<span class="keyword">return</span> <span class="built_in">getBuffer</span>(<span class="literal">true</span>, tensorName);</span><br><span class="line">&#125;</span><br><span class="line"># getBuffer函数</span><br><span class="line"><span class="function"><span class="type">void</span>* <span class="title">getBuffer</span><span class="params">(<span class="type">const</span> <span class="type">bool</span> isHost, <span class="type">const</span> std::string&amp; tensorName)</span> <span class="type">const</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">	<span class="type">int</span> index = mEngine-&gt;<span class="built_in">getBindingIndex</span>(tensorName.<span class="built_in">c_str</span>());</span><br><span class="line">	<span class="keyword">if</span> (index == <span class="number">-1</span>)</span><br><span class="line">		<span class="keyword">return</span> <span class="literal">nullptr</span>;</span><br><span class="line">	<span class="keyword">return</span> (isHost ? mManagedBuffers[index]-&gt;hostBuffer.<span class="built_in">data</span>() : mManagedBuffers[index]-&gt;deviceBuffer.<span class="built_in">data</span>());</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>会先根据名称获得张量的索引, 然后根据索引在内存管理器中找对应的数据<br>
上面两个都是获取CPU上的内存</p>
<h4 id="查找对应的数据">查找对应的数据</h4>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">void</span>* inputPointBuf = <span class="literal">nullptr</span>;</span><br><span class="line">string path = <span class="string">&quot;&quot;</span>;</span><br><span class="line">path = path + mParams.dataDirs[<span class="number">0</span>]+<span class="string">&quot;points/*.bin&quot;</span>;</span><br><span class="line">std::vector&lt;std::string&gt; filePath = <span class="built_in">glob</span>(path);</span><br></pre></td></tr></table></figure>
<p><code>glob</code>函数是查找对应文件夹中符合条件的文件</p>
<h4 id="读取点云数据">读取点云数据</h4>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span>(<span class="keyword">auto</span> idx = <span class="number">0</span>; idx &lt; filePath.<span class="built_in">size</span>(); idx++)&#123;</span><br><span class="line">	std::cout &lt;&lt; <span class="string">&quot;filePath[idx]: &quot;</span> &lt;&lt; filePath[idx] &lt;&lt; std::endl;</span><br><span class="line">	<span class="type">int</span> pointNum = <span class="number">0</span>;</span><br><span class="line">	<span class="keyword">if</span> (!<span class="built_in">processInput</span>(inputPointBuf, filePath[idx], pointNum))</span><br><span class="line">	&#123;</span><br><span class="line">		<span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	<span class="type">float</span>* points = <span class="built_in">static_cast</span>&lt;<span class="type">float</span>*&gt;(inputPointBuf);</span><br></pre></td></tr></table></figure>
<p>主要的代码是<code>processInput</code>函数:</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">bool</span> <span class="title">SampleCenterPoint::processInput</span><span class="params">(<span class="type">void</span>*&amp; inputPointBuf, std::string&amp; pointFilePath, <span class="type">int</span>&amp; pointNum)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line"></span><br><span class="line"><span class="type">bool</span> ret = <span class="built_in">readBinFile</span>(pointFilePath, inputPointBuf, pointNum);</span><br><span class="line"><span class="keyword">if</span>(!ret)&#123;</span><br><span class="line">	sample::gLogError &lt;&lt; <span class="string">&quot;Error read point file: &quot;</span> &lt;&lt; pointFilePath&lt;&lt; std::endl;</span><br><span class="line">	<span class="built_in">free</span>(inputPointBuf);</span><br><span class="line">	<span class="keyword">return</span> ret;</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">return</span> ret;</span><br><span class="line">&#125;</span><br><span class="line"># readBinFile函数代码</span><br><span class="line"><span class="function"><span class="type">bool</span> <span class="title">readBinFile</span><span class="params">(std::string&amp; filename, <span class="type">void</span>*&amp; bufPtr, <span class="type">int</span>&amp; pointNum)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="comment">// open the file:</span></span><br><span class="line">    std::streampos fileSize;</span><br><span class="line">    <span class="function">std::ifstream <span class="title">file</span><span class="params">(filename, std::ios::binary)</span></span>;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">if</span> (!file) &#123;</span><br><span class="line">        sample::gLogError &lt;&lt; <span class="string">&quot;[Error] Open file &quot;</span> &lt;&lt; filename &lt;&lt; <span class="string">&quot; failed&quot;</span> &lt;&lt; std::endl;</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// get its size:</span></span><br><span class="line">    file.<span class="built_in">seekg</span>(<span class="number">0</span>, std::ios::end);</span><br><span class="line">    fileSize = file.<span class="built_in">tellg</span>();</span><br><span class="line">    file.<span class="built_in">seekg</span>(<span class="number">0</span>, std::ios::beg);</span><br><span class="line">    </span><br><span class="line">    bufPtr = <span class="built_in">malloc</span>(fileSize);</span><br><span class="line">    <span class="keyword">if</span>(bufPtr == <span class="literal">nullptr</span>)&#123;</span><br><span class="line">        sample::gLogError &lt;&lt; <span class="string">&quot;[Error] Malloc Memory Failed! Size: &quot;</span> &lt;&lt; fileSize &lt;&lt; std::endl;</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// read the data:</span></span><br><span class="line">    file.<span class="built_in">read</span>((<span class="type">char</span>*) bufPtr, fileSize);</span><br><span class="line">    file.<span class="built_in">close</span>();</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">constexpr</span> <span class="type">int</span> featureNum = <span class="number">5</span>;</span><br><span class="line">    pointNum = fileSize /<span class="built_in">sizeof</span>(<span class="type">float</span>) / featureNum;</span><br><span class="line">    <span class="keyword">if</span>( fileSize /<span class="built_in">sizeof</span>(<span class="type">float</span>) % featureNum != <span class="number">0</span>)&#123;</span><br><span class="line">         sample::gLogError &lt;&lt; <span class="string">&quot;[Error] File Size Error! &quot;</span> &lt;&lt; fileSize &lt;&lt; std::endl;</span><br><span class="line">    &#125;</span><br><span class="line">    sample::gLogInfo &lt;&lt; <span class="string">&quot;[INFO] pointNum : &quot;</span> &lt;&lt; pointNum &lt;&lt; std::endl;</span><br><span class="line">    <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><code>std::ifstream file(filename, std::ios::binary);</code>采用二进制读取文件</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">file.<span class="built_in">seekg</span>(<span class="number">0</span>, std::ios::end);</span><br><span class="line">fileSize = file.<span class="built_in">tellg</span>();</span><br><span class="line">file.<span class="built_in">seekg</span>(<span class="number">0</span>, std::ios::beg);</span><br></pre></td></tr></table></figure>
<p>上面的代码获取文件中存储的字节数</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">bufPtr = <span class="built_in">malloc</span>(fileSize);</span><br><span class="line"><span class="keyword">if</span>(bufPtr == <span class="literal">nullptr</span>)&#123;</span><br><span class="line">	sample::gLogError &lt;&lt; <span class="string">&quot;[Error] Malloc Memory Failed! Size: &quot;</span> &lt;&lt; fileSize &lt;&lt; std::endl;</span><br><span class="line">	<span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>上面的代码是分配对应字节数的内存</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// read the data:</span></span><br><span class="line">file.<span class="built_in">read</span>((<span class="type">char</span>*) bufPtr, fileSize);</span><br><span class="line">file.<span class="built_in">close</span>();</span><br></pre></td></tr></table></figure>
<p>上面的代码从文件中读取对应的字节数到分配的内存中, 然后关闭文件</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">constexpr int featureNum = 5;</span><br><span class="line">pointNum = fileSize /sizeof(float) / featureNum;</span><br><span class="line">if( fileSize /sizeof(float) % featureNum != 0)&#123;</span><br><span class="line">	 sample::gLogError &lt;&lt; &quot;[Error] File Size Error! &quot; &lt;&lt; fileSize &lt;&lt; std::endl;</span><br><span class="line">&#125;</span><br><span class="line">sample::gLogInfo &lt;&lt; &quot;[INFO] pointNum : &quot; &lt;&lt; pointNum &lt;&lt; std::endl;</span><br><span class="line">return true;</span><br></pre></td></tr></table></figure>
<p>上面的代码就是验证字节数是不是符合要求, 因为nuscenes数据集中的点云的特征维度为5, 用float存储, 也就是说字节数肯定是整除20的</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">float</span>* points = <span class="built_in">static_cast</span>&lt;<span class="type">float</span>*&gt;(inputPointBuf);</span><br></pre></td></tr></table></figure>
<p>最后将点云从<code>void*</code>转成<code>float*</code></p>
<h4 id="预处理数据">预处理数据</h4>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">std::vector&lt;Box&gt; predResult;</span><br><span class="line"></span><br><span class="line"><span class="keyword">auto</span> startTime = std::chrono::high_resolution_clock::<span class="built_in">now</span>();</span><br><span class="line"><span class="built_in">preprocess</span>(points, hostPillars, hostIndex, pointNum);</span><br><span class="line"><span class="keyword">auto</span> endTime = std::chrono::high_resolution_clock::<span class="built_in">now</span>();</span><br><span class="line"><span class="type">double</span> preprocessDuration = std::chrono::<span class="built_in">duration_cast</span>&lt;std::chrono::nanoseconds&gt;(endTime - startTime).<span class="built_in">count</span>()/<span class="number">1000000.0</span>;</span><br></pre></td></tr></table></figure>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">std::vector&lt;Box&gt; predResult;</span><br><span class="line"># Box结构体定义如下</span><br><span class="line"></span><br><span class="line"><span class="keyword">struct</span> <span class="title class_">Box</span>&#123;</span><br><span class="line">    <span class="type">float</span> x;</span><br><span class="line">    <span class="type">float</span> y;</span><br><span class="line">    <span class="type">float</span> z;</span><br><span class="line">    <span class="type">float</span> l;</span><br><span class="line">    <span class="type">float</span> h;</span><br><span class="line">    <span class="type">float</span> w;</span><br><span class="line">    <span class="type">float</span> velX;</span><br><span class="line">    <span class="type">float</span> velY;</span><br><span class="line">    <span class="type">float</span> theta;</span><br><span class="line"></span><br><span class="line">    <span class="type">float</span> score;</span><br><span class="line">    <span class="type">int</span> cls;</span><br><span class="line">    <span class="type">bool</span> isDrop; <span class="comment">// for nms</span></span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>
<p>创建一个由包围框组成的vector</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">auto</span> startTime = std::chrono::high_resolution_clock::<span class="built_in">now</span>();</span><br><span class="line"><span class="built_in">preprocess</span>(points, hostPillars, hostIndex, pointNum);</span><br><span class="line"><span class="keyword">auto</span> endTime = std::chrono::high_resolution_clock::<span class="built_in">now</span>();</span><br><span class="line"><span class="type">double</span> preprocessDuration = std::chrono::<span class="built_in">duration_cast</span>&lt;std::chrono::nanoseconds&gt;(endTime - startTime).<span class="built_in">count</span>()/<span class="number">1000000.0</span>;</span><br></pre></td></tr></table></figure>
<p>上面的代码进行预处理并计算预处理的时间<br>
<code>preprocess</code>的代码如下</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">void</span> <span class="title">preprocess</span><span class="params">(<span class="type">float</span>* points, <span class="type">float</span>* feature, <span class="type">int</span>* indices, <span class="type">int</span> pointNum)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> idx=<span class="number">0</span>; idx&lt; MAX_PILLARS*<span class="number">2</span>; idx++)&#123;</span><br><span class="line">        indices[idx] = <span class="number">-1</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> idx=<span class="number">0</span>; idx&lt; MAX_PILLARS*FEATURE_NUM*MAX_PIONT_IN_PILLARS; idx++)&#123;</span><br><span class="line">        feature[idx] = <span class="number">0</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    std::vector&lt;std::thread&gt; threadPool;</span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> idx=<span class="number">0</span>; idx &lt; THREAD_NUM; idx++)&#123;</span><br><span class="line">        <span class="function">std::thread <span class="title">worker</span><span class="params">(PreprocessWorker,</span></span></span><br><span class="line"><span class="params"><span class="function">                                             points,</span></span></span><br><span class="line"><span class="params"><span class="function">                                             feature,</span></span></span><br><span class="line"><span class="params"><span class="function">                                             indices,</span></span></span><br><span class="line"><span class="params"><span class="function">                                             pointNum,</span></span></span><br><span class="line"><span class="params"><span class="function">                                             idx,</span></span></span><br><span class="line"><span class="params"><span class="function">                                             MAX_PILLARS/THREAD_NUM</span></span></span><br><span class="line"><span class="params"><span class="function">                                             )</span></span>;</span><br><span class="line">        </span><br><span class="line">        threadPool.<span class="built_in">push_back</span>(std::<span class="built_in">move</span>(worker));</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span>(<span class="keyword">auto</span> idx=<span class="number">0</span>; idx &lt; THREAD_NUM; idx++)&#123;</span><br><span class="line">        threadPool[idx].<span class="built_in">join</span>();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span>(<span class="type">int</span> idx=<span class="number">0</span>; idx&lt; MAX_PILLARS*<span class="number">2</span>; idx++)&#123;</span><br><span class="line">	indices[idx] = <span class="number">-1</span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">for</span>(<span class="type">int</span> idx=<span class="number">0</span>; idx&lt; MAX_PILLARS*FEATURE_NUM*MAX_PIONT_IN_PILLARS; idx++)&#123;</span><br><span class="line">	feature[idx] = <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>上面的代码先对<code>indices</code>和<code>feature</code>进行了初始化</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">std::vector&lt;std::thread&gt; threadPool;</span><br><span class="line"><span class="keyword">for</span>(<span class="type">int</span> idx=<span class="number">0</span>; idx &lt; THREAD_NUM; idx++)&#123;</span><br><span class="line">	<span class="function">std::thread <span class="title">worker</span><span class="params">(PreprocessWorker,</span></span></span><br><span class="line"><span class="params"><span class="function">										 points,</span></span></span><br><span class="line"><span class="params"><span class="function">										 feature,</span></span></span><br><span class="line"><span class="params"><span class="function">										 indices,</span></span></span><br><span class="line"><span class="params"><span class="function">										 pointNum,</span></span></span><br><span class="line"><span class="params"><span class="function">										 idx,</span></span></span><br><span class="line"><span class="params"><span class="function">										 MAX_PILLARS/THREAD_NUM</span></span></span><br><span class="line"><span class="params"><span class="function">										 )</span></span>;</span><br><span class="line"></span><br><span class="line">	threadPool.<span class="built_in">push_back</span>(std::<span class="built_in">move</span>(worker));</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span>(<span class="keyword">auto</span> idx=<span class="number">0</span>; idx &lt; THREAD_NUM; idx++)&#123;</span><br><span class="line">	threadPool[idx].<span class="built_in">join</span>();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>上面的代码使用线程池来进行处理, 但是实测下来, 会出错, 还是不用线程比较好<br>
可以参考这个<a target="_blank" rel="noopener" href="https://github.com/CarkusL/CenterPoint/issues/12">issue</a>, 里面的回答也是我哈哈哈<br>
<code>PreprocessWorker</code>代码如下</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">void</span> <span class="title">PreprocessWorker</span><span class="params">(<span class="type">float</span>* points, <span class="type">float</span>* feature, <span class="type">int</span>* indices, <span class="type">int</span> pointNum, <span class="type">int</span> threadIdx, <span class="type">int</span> pillarsPerThread)</span></span>&#123;</span><br><span class="line">    <span class="comment">// 0 ~ MAX_PIONT_IN_PILLARS</span></span><br><span class="line">    <span class="type">unsigned</span> <span class="type">short</span> pointCount[MAX_PILLARS] = &#123;<span class="number">0</span>&#125;;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 0 ~ MAX_PILLARS</span></span><br><span class="line">    <span class="type">int</span> pillarsIndices[BEV_W*BEV_H] = &#123;<span class="number">0</span>&#125;;</span><br><span class="line">    <span class="keyword">for</span>(<span class="type">size_t</span> idx = <span class="number">0</span>; idx &lt; BEV_W*BEV_H; idx++)&#123;</span><br><span class="line">        pillarsIndices[idx] = <span class="number">-1</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="type">int</span> pillarCount = threadIdx*pillarsPerThread;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> idx = <span class="number">0</span>; idx &lt; pointNum; idx++)&#123;</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">auto</span> x = points[idx*<span class="number">5</span>];</span><br><span class="line">        <span class="keyword">auto</span> y = points[idx*<span class="number">5</span>+<span class="number">1</span>];</span><br><span class="line">        <span class="keyword">auto</span> z = points[idx*<span class="number">5</span>+<span class="number">2</span>];</span><br><span class="line">        <span class="keyword">if</span>(x &lt; X_MIN || x &gt; X_MAX || y &lt; Y_MIN || y &gt; Y_MAX || </span><br><span class="line">           z &lt; Z_MIN || z &gt; Z_MAX)</span><br><span class="line">           <span class="keyword">continue</span>;</span><br><span class="line"></span><br><span class="line">        <span class="type">int</span> xIdx = <span class="built_in">int</span>((x-X_MIN)/X_STEP);</span><br><span class="line">        <span class="type">int</span> yIdx = <span class="built_in">int</span>((y-Y_MIN)/Y_STEP);</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">if</span>(xIdx % THREAD_NUM != threadIdx)</span><br><span class="line">            <span class="keyword">continue</span>;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        <span class="type">int</span> pillarIdx = yIdx*BEV_W+xIdx;</span><br><span class="line">        <span class="keyword">auto</span> pillarCountIdx = pillarsIndices[pillarIdx];</span><br><span class="line"></span><br><span class="line">        <span class="keyword">auto</span> pointNumInPillar = pointCount[pillarCountIdx];</span><br><span class="line">        <span class="keyword">if</span>(pointNumInPillar &gt; MAX_PIONT_IN_PILLARS - <span class="number">1</span>)</span><br><span class="line">           <span class="keyword">continue</span>;</span><br><span class="line">  </span><br><span class="line">        <span class="comment">// new pillar index</span></span><br><span class="line">        <span class="keyword">if</span>(pillarCountIdx == <span class="number">-1</span>)&#123;</span><br><span class="line">            pillarCountIdx = pillarCount;</span><br><span class="line">            pillarsIndices[pillarIdx] = pillarCount;</span><br><span class="line">            indices[pillarCount*<span class="number">2</span> + <span class="number">1</span>] = pillarIdx;</span><br><span class="line">            ++pillarCount;</span><br><span class="line">        &#125;</span><br><span class="line"> </span><br><span class="line">        feature[                                     pillarCountIdx*MAX_PIONT_IN_PILLARS + pointNumInPillar] = x;</span><br><span class="line">        feature[<span class="number">1</span>*MAX_PILLARS*MAX_PIONT_IN_PILLARS + pillarCountIdx*MAX_PIONT_IN_PILLARS + pointNumInPillar] = y;</span><br><span class="line">        feature[<span class="number">2</span>*MAX_PILLARS*MAX_PIONT_IN_PILLARS + pillarCountIdx*MAX_PIONT_IN_PILLARS + pointNumInPillar] = z; <span class="comment">// z</span></span><br><span class="line">        feature[<span class="number">3</span>*MAX_PILLARS*MAX_PIONT_IN_PILLARS + pillarCountIdx*MAX_PIONT_IN_PILLARS + pointNumInPillar] = points[idx*<span class="number">5</span>+<span class="number">3</span>]; <span class="comment">// instence</span></span><br><span class="line">        feature[<span class="number">4</span>*MAX_PILLARS*MAX_PIONT_IN_PILLARS + pillarCountIdx*MAX_PIONT_IN_PILLARS + pointNumInPillar] = points[idx*<span class="number">5</span>+<span class="number">4</span>]; <span class="comment">// time_lag</span></span><br><span class="line"></span><br><span class="line">        feature[<span class="number">8</span>*MAX_PILLARS*MAX_PIONT_IN_PILLARS + pillarCountIdx*MAX_PIONT_IN_PILLARS + pointNumInPillar] = x - (xIdx*X_STEP + X_MIN + X_STEP/<span class="number">2</span>);</span><br><span class="line">        feature[<span class="number">9</span>*MAX_PILLARS*MAX_PIONT_IN_PILLARS + pillarCountIdx*MAX_PIONT_IN_PILLARS + pointNumInPillar] = y - (yIdx*Y_STEP + Y_MIN + Y_STEP/<span class="number">2</span>);</span><br><span class="line"></span><br><span class="line">        ++pointNumInPillar;</span><br><span class="line">        pointCount[pillarCountIdx] = pointNumInPillar;</span><br><span class="line">        </span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> pillarIdx = threadIdx*pillarsPerThread; pillarIdx &lt; (threadIdx+<span class="number">1</span>)*pillarsPerThread; pillarIdx++)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="type">float</span> xCenter = <span class="number">0</span>;</span><br><span class="line">        <span class="type">float</span> yCenter = <span class="number">0</span>;</span><br><span class="line">        <span class="type">float</span> zCenter = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">auto</span> pointNum = pointCount[pillarIdx];</span><br><span class="line">        <span class="keyword">for</span>(<span class="type">int</span> pointIdx=<span class="number">0</span>; pointIdx &lt; pointNum; pointIdx++)</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="keyword">auto</span> x = feature[                                     pillarIdx*MAX_PIONT_IN_PILLARS + pointIdx];</span><br><span class="line">            <span class="keyword">auto</span> y = feature[<span class="number">1</span>*MAX_PILLARS*MAX_PIONT_IN_PILLARS + pillarIdx*MAX_PIONT_IN_PILLARS + pointIdx];</span><br><span class="line">            <span class="keyword">auto</span> z = feature[<span class="number">2</span>*MAX_PILLARS*MAX_PIONT_IN_PILLARS + pillarIdx*MAX_PIONT_IN_PILLARS + pointIdx];</span><br><span class="line">            xCenter += x;</span><br><span class="line">            yCenter += y;</span><br><span class="line">            zCenter += z;</span><br><span class="line">        &#125;</span><br><span class="line">        xCenter = xCenter / pointNum;</span><br><span class="line">        yCenter = yCenter / pointNum;</span><br><span class="line">        zCenter = zCenter / pointNum;</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">for</span>(<span class="type">int</span> pointIdx=<span class="number">0</span>; pointIdx &lt; pointNum; pointIdx++)</span><br><span class="line">        &#123;    </span><br><span class="line">            <span class="keyword">auto</span> x = feature[                                     pillarIdx*MAX_PIONT_IN_PILLARS + pointIdx];</span><br><span class="line">            <span class="keyword">auto</span> y = feature[<span class="number">1</span>*MAX_PILLARS*MAX_PIONT_IN_PILLARS + pillarIdx*MAX_PIONT_IN_PILLARS + pointIdx];</span><br><span class="line">            <span class="keyword">auto</span> z = feature[<span class="number">2</span>*MAX_PILLARS*MAX_PIONT_IN_PILLARS + pillarIdx*MAX_PIONT_IN_PILLARS + pointIdx];</span><br><span class="line">       </span><br><span class="line">            feature[<span class="number">5</span>*MAX_PILLARS*MAX_PIONT_IN_PILLARS + pillarIdx*MAX_PIONT_IN_PILLARS + pointIdx] = x - xCenter;</span><br><span class="line">            feature[<span class="number">6</span>*MAX_PILLARS*MAX_PIONT_IN_PILLARS + pillarIdx*MAX_PIONT_IN_PILLARS + pointIdx] = y - yCenter;</span><br><span class="line">            feature[<span class="number">7</span>*MAX_PILLARS*MAX_PIONT_IN_PILLARS + pillarIdx*MAX_PIONT_IN_PILLARS + pointIdx] = z - zCenter;</span><br><span class="line"></span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>上面的代码就不细说了, 和python中的voxelization的操作是一致的, 只不过变成了指针操作</p>
<h4 id="将输入拷贝至gpu上">将输入拷贝至GPU上</h4>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">buffers.<span class="built_in">copyInputToDevice</span>();</span><br><span class="line"># copyInputToDevice函数定义</span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">copyInputToDevice</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">	<span class="built_in">memcpyBuffers</span>(<span class="literal">true</span>, <span class="literal">false</span>, <span class="literal">false</span>);</span><br><span class="line">&#125;</span><br><span class="line"># memcpyBuffers定义</span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">memcpyBuffers</span><span class="params">(<span class="type">const</span> <span class="type">bool</span> copyInput, <span class="type">const</span> <span class="type">bool</span> deviceToHost, <span class="type">const</span> <span class="type">bool</span> async, <span class="type">const</span> cudaStream_t&amp; stream = <span class="number">0</span>)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">	<span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; mEngine-&gt;<span class="built_in">getNbBindings</span>(); i++)</span><br><span class="line">	&#123;</span><br><span class="line">		<span class="type">void</span>* dstPtr</span><br><span class="line">			= deviceToHost ? mManagedBuffers[i]-&gt;hostBuffer.<span class="built_in">data</span>() : mManagedBuffers[i]-&gt;deviceBuffer.<span class="built_in">data</span>();</span><br><span class="line">		<span class="type">const</span> <span class="type">void</span>* srcPtr</span><br><span class="line">			= deviceToHost ? mManagedBuffers[i]-&gt;deviceBuffer.<span class="built_in">data</span>() : mManagedBuffers[i]-&gt;hostBuffer.<span class="built_in">data</span>();</span><br><span class="line">		<span class="type">const</span> <span class="type">size_t</span> byteSize = mManagedBuffers[i]-&gt;hostBuffer.<span class="built_in">nbBytes</span>();</span><br><span class="line">		<span class="type">const</span> cudaMemcpyKind memcpyType = deviceToHost ? cudaMemcpyDeviceToHost : cudaMemcpyHostToDevice;</span><br><span class="line">		<span class="keyword">if</span> ((copyInput &amp;&amp; mEngine-&gt;<span class="built_in">bindingIsInput</span>(i)) || (!copyInput &amp;&amp; !mEngine-&gt;<span class="built_in">bindingIsInput</span>(i)))</span><br><span class="line">		&#123;</span><br><span class="line">			<span class="keyword">if</span> (async)</span><br><span class="line">				<span class="built_in">CHECK</span>(<span class="built_in">cudaMemcpyAsync</span>(dstPtr, srcPtr, byteSize, memcpyType, stream));</span><br><span class="line">			<span class="keyword">else</span></span><br><span class="line">				<span class="built_in">CHECK</span>(<span class="built_in">cudaMemcpy</span>(dstPtr, srcPtr, byteSize, memcpyType));</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>如果<code>deviceToHost</code>是True就是将CPU的数据拷贝到GPU, 否则就是将GPU的数据拷贝到CPU<br>
<code>copyInput</code>用来确定是复制输入还是复制输出</p>
<h4 id="运行模型">运行模型</h4>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">bool</span> status = context-&gt;<span class="built_in">executeV2</span>(buffers.<span class="built_in">getDeviceBindings</span>().<span class="built_in">data</span>());</span><br><span class="line"><span class="keyword">if</span> (!status)</span><br><span class="line">&#123;</span><br><span class="line">	<span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>直接调用<code>context-&gt;executeV2</code>就可以运行模型</p>
<h4 id="将输出复制到cpu">将输出复制到CPU</h4>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">buffers.<span class="built_in">copyOutputToHost</span>();</span><br><span class="line"># copyOutputToHost定义</span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">copyOutputToHost</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">	<span class="built_in">memcpyBuffers</span>(<span class="literal">false</span>, <span class="literal">true</span>, <span class="literal">false</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>就是吧输出复制到CPU上</p>
<h4 id="后处理数据">后处理数据</h4>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">postprocess</span>(buffers, predResult);</span><br><span class="line"><span class="meta"># postprocess代码</span></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">postprocess</span><span class="params">(<span class="type">const</span> samplesCommon::BufferManager&amp; buffers, std::vector&lt;Box&gt;&amp; predResult)</span></span>&#123;</span><br><span class="line"></span><br><span class="line">    std::vector&lt;std::string&gt; regName&#123;   <span class="string">&quot;594&quot;</span>, <span class="string">&quot;618&quot;</span>, <span class="string">&quot;642&quot;</span>, <span class="string">&quot;666&quot;</span>, <span class="string">&quot;690&quot;</span>, <span class="string">&quot;714&quot;</span>&#125;;</span><br><span class="line">    std::vector&lt;std::string&gt; heightName&#123;<span class="string">&quot;598&quot;</span>, <span class="string">&quot;622&quot;</span>, <span class="string">&quot;646&quot;</span>, <span class="string">&quot;670&quot;</span>, <span class="string">&quot;694&quot;</span>, <span class="string">&quot;718&quot;</span>&#125;;</span><br><span class="line">    std::vector&lt;std::string&gt; rotName&#123;   <span class="string">&quot;606&quot;</span>, <span class="string">&quot;630&quot;</span>, <span class="string">&quot;654&quot;</span>, <span class="string">&quot;678&quot;</span>, <span class="string">&quot;702&quot;</span>, <span class="string">&quot;726&quot;</span>&#125;;</span><br><span class="line">    std::vector&lt;std::string&gt; velName&#123;   <span class="string">&quot;610&quot;</span>, <span class="string">&quot;634&quot;</span>, <span class="string">&quot;658&quot;</span>, <span class="string">&quot;682&quot;</span>, <span class="string">&quot;706&quot;</span>, <span class="string">&quot;730&quot;</span>&#125;;</span><br><span class="line">    std::vector&lt;std::string&gt; dimName&#123;   <span class="string">&quot;736&quot;</span>, <span class="string">&quot;740&quot;</span>, <span class="string">&quot;744&quot;</span>, <span class="string">&quot;748&quot;</span>, <span class="string">&quot;752&quot;</span>, <span class="string">&quot;756&quot;</span>&#125;;</span><br><span class="line">    std::vector&lt;std::string&gt; scoreName&#123; <span class="string">&quot;737&quot;</span>, <span class="string">&quot;741&quot;</span>, <span class="string">&quot;745&quot;</span>, <span class="string">&quot;749&quot;</span>, <span class="string">&quot;753&quot;</span>, <span class="string">&quot;757&quot;</span>&#125;;</span><br><span class="line">    std::vector&lt;std::string&gt; clsName&#123;   <span class="string">&quot;738&quot;</span>, <span class="string">&quot;742&quot;</span>, <span class="string">&quot;746&quot;</span>, <span class="string">&quot;750&quot;</span>, <span class="string">&quot;754&quot;</span>, <span class="string">&quot;758&quot;</span>&#125;;</span><br><span class="line">    <span class="type">int</span> clsOffsetPerTask[] = &#123;<span class="number">0</span>, <span class="number">1</span>, <span class="number">3</span>, <span class="number">5</span>, <span class="number">6</span>, <span class="number">8</span>&#125;;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span> (<span class="type">size_t</span> taskIdx = <span class="number">0</span>; taskIdx &lt; TASK_NUM; taskIdx++)&#123;</span><br><span class="line">        std::vector&lt;Box&gt; predBoxs;</span><br><span class="line">        </span><br><span class="line">        <span class="type">float</span>* reg = <span class="built_in">static_cast</span>&lt;<span class="type">float</span>*&gt;(buffers.<span class="built_in">getHostBuffer</span>(regName[taskIdx]));</span><br><span class="line">        <span class="type">float</span>* height = <span class="built_in">static_cast</span>&lt;<span class="type">float</span>*&gt;(buffers.<span class="built_in">getHostBuffer</span>(heightName[taskIdx]));</span><br><span class="line">        <span class="type">float</span>* rot = <span class="built_in">static_cast</span>&lt;<span class="type">float</span>*&gt;(buffers.<span class="built_in">getHostBuffer</span>(rotName[taskIdx]));</span><br><span class="line">        <span class="type">float</span>* vel = <span class="built_in">static_cast</span>&lt;<span class="type">float</span>*&gt;(buffers.<span class="built_in">getHostBuffer</span>(velName[taskIdx]));</span><br><span class="line">        <span class="type">float</span>* dim = <span class="built_in">static_cast</span>&lt;<span class="type">float</span>*&gt;(buffers.<span class="built_in">getHostBuffer</span>(dimName[taskIdx]));</span><br><span class="line">        <span class="type">float</span>* score = <span class="built_in">static_cast</span>&lt;<span class="type">float</span>*&gt;(buffers.<span class="built_in">getHostBuffer</span>(scoreName[taskIdx]));</span><br><span class="line">        <span class="type">int32_t</span>* cls = <span class="built_in">static_cast</span>&lt;<span class="type">int32_t</span>*&gt;(buffers.<span class="built_in">getHostBuffer</span>(clsName[taskIdx]));</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span>(<span class="type">size_t</span> yIdx=<span class="number">0</span>; yIdx &lt; OUTPUT_H; yIdx++)&#123;</span><br><span class="line">            <span class="keyword">for</span>(<span class="type">size_t</span> xIdx=<span class="number">0</span>; xIdx &lt; OUTPUT_W; xIdx++)&#123;</span><br><span class="line">                <span class="keyword">auto</span> idx = yIdx* OUTPUT_W + xIdx;</span><br><span class="line">                <span class="keyword">if</span>(score[idx] &lt; SCORE_THREAHOLD)</span><br><span class="line">                    <span class="keyword">continue</span>;</span><br><span class="line">                </span><br><span class="line">                <span class="type">float</span> x = (xIdx + reg[<span class="number">0</span>*OUTPUT_H*OUTPUT_W + idx])*OUT_SIZE_FACTOR*X_STEP + X_MIN;</span><br><span class="line">                <span class="type">float</span> y = (yIdx + reg[<span class="number">1</span>*OUTPUT_H*OUTPUT_W + idx])*OUT_SIZE_FACTOR*Y_STEP + Y_MIN;</span><br><span class="line">                <span class="type">float</span> z = height[idx];</span><br><span class="line"></span><br><span class="line">                <span class="keyword">if</span>(x &lt; X_MIN || x &gt; X_MAX || y &lt; Y_MIN || y &gt; Y_MAX || z &lt; Z_MIN || z &gt; Z_MAX)</span><br><span class="line">                    <span class="keyword">continue</span>;</span><br><span class="line">                </span><br><span class="line">                Box box;</span><br><span class="line">                box.x = x;</span><br><span class="line">                box.y = y;</span><br><span class="line">                box.z = z;</span><br><span class="line">                box.l = dim[<span class="number">0</span>*OUTPUT_H*OUTPUT_W + idx];</span><br><span class="line">                box.h = dim[<span class="number">1</span>*OUTPUT_H*OUTPUT_W + idx];</span><br><span class="line">                box.w = dim[<span class="number">2</span>*OUTPUT_H*OUTPUT_W + idx];</span><br><span class="line">                box.theta = <span class="built_in">atan2</span>(rot[<span class="number">0</span>*OUTPUT_H*OUTPUT_W + idx], rot[<span class="number">1</span>*OUTPUT_H*OUTPUT_W + idx]);</span><br><span class="line">                box.velX = vel[<span class="number">0</span>*OUTPUT_H*OUTPUT_W+idx];</span><br><span class="line">                box.velY = vel[<span class="number">1</span>*OUTPUT_H*OUTPUT_W+idx];</span><br><span class="line">                <span class="comment">// box.theta = box.theta - PI /2;</span></span><br><span class="line"></span><br><span class="line">                box.score = score[idx];</span><br><span class="line">                box.cls = cls[idx] + clsOffsetPerTask[taskIdx];</span><br><span class="line">                box.isDrop = <span class="literal">false</span>;</span><br><span class="line"></span><br><span class="line">                predBoxs.<span class="built_in">push_back</span>(box);</span><br><span class="line"></span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        </span><br><span class="line">        <span class="built_in">AlignedNMSBev</span>(predBoxs);</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">auto</span> idx =<span class="number">0</span>; idx &lt; predBoxs.<span class="built_in">size</span>(); idx++)&#123;</span><br><span class="line">            <span class="keyword">if</span>(!predBoxs[idx].isDrop)</span><br><span class="line">                predResult.<span class="built_in">push_back</span>(predBoxs[idx]);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">std::vector&lt;std::string&gt; regName&#123;   <span class="string">&quot;594&quot;</span>, <span class="string">&quot;618&quot;</span>, <span class="string">&quot;642&quot;</span>, <span class="string">&quot;666&quot;</span>, <span class="string">&quot;690&quot;</span>, <span class="string">&quot;714&quot;</span>&#125;;</span><br><span class="line">std::vector&lt;std::string&gt; heightName&#123;<span class="string">&quot;598&quot;</span>, <span class="string">&quot;622&quot;</span>, <span class="string">&quot;646&quot;</span>, <span class="string">&quot;670&quot;</span>, <span class="string">&quot;694&quot;</span>, <span class="string">&quot;718&quot;</span>&#125;;</span><br><span class="line">std::vector&lt;std::string&gt; rotName&#123;   <span class="string">&quot;606&quot;</span>, <span class="string">&quot;630&quot;</span>, <span class="string">&quot;654&quot;</span>, <span class="string">&quot;678&quot;</span>, <span class="string">&quot;702&quot;</span>, <span class="string">&quot;726&quot;</span>&#125;;</span><br><span class="line">std::vector&lt;std::string&gt; velName&#123;   <span class="string">&quot;610&quot;</span>, <span class="string">&quot;634&quot;</span>, <span class="string">&quot;658&quot;</span>, <span class="string">&quot;682&quot;</span>, <span class="string">&quot;706&quot;</span>, <span class="string">&quot;730&quot;</span>&#125;;</span><br><span class="line">std::vector&lt;std::string&gt; dimName&#123;   <span class="string">&quot;736&quot;</span>, <span class="string">&quot;740&quot;</span>, <span class="string">&quot;744&quot;</span>, <span class="string">&quot;748&quot;</span>, <span class="string">&quot;752&quot;</span>, <span class="string">&quot;756&quot;</span>&#125;;</span><br><span class="line">std::vector&lt;std::string&gt; scoreName&#123; <span class="string">&quot;737&quot;</span>, <span class="string">&quot;741&quot;</span>, <span class="string">&quot;745&quot;</span>, <span class="string">&quot;749&quot;</span>, <span class="string">&quot;753&quot;</span>, <span class="string">&quot;757&quot;</span>&#125;;</span><br><span class="line">std::vector&lt;std::string&gt; clsName&#123;   <span class="string">&quot;738&quot;</span>, <span class="string">&quot;742&quot;</span>, <span class="string">&quot;746&quot;</span>, <span class="string">&quot;750&quot;</span>, <span class="string">&quot;754&quot;</span>, <span class="string">&quot;758&quot;</span>&#125;;</span><br></pre></td></tr></table></figure>
<p>上面的代码表示了每个类别的输出的名称</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> (<span class="type">size_t</span> taskIdx = <span class="number">0</span>; taskIdx &lt; TASK_NUM; taskIdx++)&#123;</span><br></pre></td></tr></table></figure>
<p>for循环遍历每个类别</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">float</span>* reg = <span class="built_in">static_cast</span>&lt;<span class="type">float</span>*&gt;(buffers.<span class="built_in">getHostBuffer</span>(regName[taskIdx]));</span><br><span class="line"><span class="type">float</span>* height = <span class="built_in">static_cast</span>&lt;<span class="type">float</span>*&gt;(buffers.<span class="built_in">getHostBuffer</span>(heightName[taskIdx]));</span><br><span class="line"><span class="type">float</span>* rot = <span class="built_in">static_cast</span>&lt;<span class="type">float</span>*&gt;(buffers.<span class="built_in">getHostBuffer</span>(rotName[taskIdx]));</span><br><span class="line"><span class="type">float</span>* vel = <span class="built_in">static_cast</span>&lt;<span class="type">float</span>*&gt;(buffers.<span class="built_in">getHostBuffer</span>(velName[taskIdx]));</span><br><span class="line"><span class="type">float</span>* dim = <span class="built_in">static_cast</span>&lt;<span class="type">float</span>*&gt;(buffers.<span class="built_in">getHostBuffer</span>(dimName[taskIdx]));</span><br><span class="line"><span class="type">float</span>* score = <span class="built_in">static_cast</span>&lt;<span class="type">float</span>*&gt;(buffers.<span class="built_in">getHostBuffer</span>(scoreName[taskIdx]));</span><br><span class="line"><span class="type">int32_t</span>* cls = <span class="built_in">static_cast</span>&lt;<span class="type">int32_t</span>*&gt;(buffers.<span class="built_in">getHostBuffer</span>(clsName[taskIdx]));</span><br></pre></td></tr></table></figure>
<p>上面的代码获取每个类别的输出</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span>(<span class="type">size_t</span> yIdx=<span class="number">0</span>; yIdx &lt; OUTPUT_H; yIdx++)&#123;</span><br><span class="line">            <span class="keyword">for</span>(<span class="type">size_t</span> xIdx=<span class="number">0</span>; xIdx &lt; OUTPUT_W; xIdx++)&#123;</span><br></pre></td></tr></table></figure>
<p>上面的代码遍历特征图的每一个位置</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">auto</span> idx = yIdx* OUTPUT_W + xIdx;</span><br><span class="line">                <span class="keyword">if</span>(score[idx] &lt; SCORE_THREAHOLD)</span><br><span class="line">                    <span class="keyword">continue</span>;</span><br></pre></td></tr></table></figure>
<p>上面的代码获取这个位置上的物体的分数, 如果分数小于阈值, 就跳过</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">float</span> x = (xIdx + reg[<span class="number">0</span>*OUTPUT_H*OUTPUT_W + idx])*OUT_SIZE_FACTOR*X_STEP + X_MIN;</span><br><span class="line">                <span class="type">float</span> y = (yIdx + reg[<span class="number">1</span>*OUTPUT_H*OUTPUT_W + idx])*OUT_SIZE_FACTOR*Y_STEP + Y_MIN;</span><br><span class="line">                <span class="type">float</span> z = height[idx];</span><br><span class="line"></span><br><span class="line">                <span class="keyword">if</span>(x &lt; X_MIN || x &gt; X_MAX || y &lt; Y_MIN || y &gt; Y_MAX || z &lt; Z_MIN || z &gt; Z_MAX)</span><br><span class="line">                    <span class="keyword">continue</span>;</span><br></pre></td></tr></table></figure>
<p>上面的代码获取包围框的坐标, 如果超过了返回就跳过</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">Box box;</span><br><span class="line">box.x = x;</span><br><span class="line">box.y = y;</span><br><span class="line">box.z = z;</span><br><span class="line">box.l = dim[<span class="number">0</span>*OUTPUT_H*OUTPUT_W + idx];</span><br><span class="line">box.h = dim[<span class="number">1</span>*OUTPUT_H*OUTPUT_W + idx];</span><br><span class="line">box.w = dim[<span class="number">2</span>*OUTPUT_H*OUTPUT_W + idx];</span><br><span class="line">box.theta = <span class="built_in">atan2</span>(rot[<span class="number">0</span>*OUTPUT_H*OUTPUT_W + idx], rot[<span class="number">1</span>*OUTPUT_H*OUTPUT_W + idx]);</span><br><span class="line">box.velX = vel[<span class="number">0</span>*OUTPUT_H*OUTPUT_W+idx];</span><br><span class="line">box.velY = vel[<span class="number">1</span>*OUTPUT_H*OUTPUT_W+idx];</span><br><span class="line"><span class="comment">// box.theta = box.theta - PI /2;</span></span><br><span class="line"></span><br><span class="line">box.score = score[idx];</span><br><span class="line">box.cls = cls[idx] + clsOffsetPerTask[taskIdx];</span><br><span class="line">box.isDrop = <span class="literal">false</span>;</span><br><span class="line"></span><br><span class="line">predBoxs.<span class="built_in">push_back</span>(box);</span><br></pre></td></tr></table></figure>
<p>填充包围框, 其中<code>box.cls = cls[idx] + clsOffsetPerTask[taskIdx];</code>是加入了类别的开始和偏移</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">int</span> clsOffsetPerTask[] = &#123;<span class="number">0</span>, <span class="number">1</span>, <span class="number">3</span>, <span class="number">5</span>, <span class="number">6</span>, <span class="number">8</span>&#125;;</span><br></pre></td></tr></table></figure>
<p>比如第一个大类有一个类, 第二个大类有2个类, 第三个大类有2个类, 第四个大类有一个类, 第五个大类有2个类, 第六个大类有两个类</p>
<p><strong>NMS操作</strong></p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">AlignedNMSBev</span>(predBoxs);</span><br></pre></td></tr></table></figure>
<p>这个代码是对旋转物体计算NMS, 主要涉及计算旋转物体的IoU, 后面会专门出一个博客讲讲怎么求旋转物体的IoU</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span>(<span class="keyword">auto</span> idx =<span class="number">0</span>; idx &lt; predBoxs.<span class="built_in">size</span>(); idx++)&#123;</span><br><span class="line">	<span class="keyword">if</span>(!predBoxs[idx].isDrop)</span><br><span class="line">		predResult.<span class="built_in">push_back</span>(predBoxs[idx]);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>上面的代码将过滤后的物体加入检测列表中</p>
<h1 id="总结">总结</h1>
<p>还是一个部署入门的很好的项目, 值得学习</p>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta"><i class="fas fa-circle-user fa-fw"></i>文章作者: </span><span class="post-copyright-info"><a href="https://zhangtingyu11.github.io">Grapymage</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta"><i class="fas fa-square-arrow-up-right fa-fw"></i>文章链接: </span><span class="post-copyright-info"><a href="https://zhangtingyu11.github.io/2024/05/18/cuda_programming/tensorrt_centerpoint/">https://zhangtingyu11.github.io/2024/05/18/cuda_programming/tensorrt_centerpoint/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta"><i class="fas fa-circle-exclamation fa-fw"></i>版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="https://zhangtingyu11.github.io" target="_blank">Grapymage的个人博客</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/TensorRT/">TensorRT</a></div><div class="post_share"><div class="social-share" data-image="/img/avatar.jpeg" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><div class="post-reward"><div class="reward-button"><i class="fas fa-qrcode"></i>赞助</div><div class="reward-main"><ul class="reward-all"><li class="reward-item"><a href="/img/wechat.jpg" target="_blank"><img class="post-qr-code-img" src="/img/wechat.jpg" alt="wechat"/></a><div class="post-qr-code-desc">wechat</div></li><li class="reward-item"><a href="/img/alipay.jpg" target="_blank"><img class="post-qr-code-img" src="/img/alipay.jpg" alt="alipay"/></a><div class="post-qr-code-desc">alipay</div></li></ul></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/2024/05/19/lab_env_construction/yolov5/" title="Yolov5环境搭建"><div class="cover" style="background: var(--default-bg-color)"></div><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">Yolov5环境搭建</div></div></a></div><div class="next-post pull-right"><a href="/2024/05/16/cpp/vscode_debug_cpp/" title="VSCode调试C++代码"><div class="cover" style="background: var(--default-bg-color)"></div><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">VSCode调试C++代码</div></div></a></div></nav><hr class="custom-hr"/><div id="post-comment"><div class="comment-head"><div class="comment-headline"><i class="fas fa-comments fa-fw"></i><span> 评论</span></div></div><div class="comment-wrap"><div><div id="twikoo-wrap"></div></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src="/img/avatar.jpeg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info__name">Grapymage</div><div class="author-info__description"></div></div><div class="card-info-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">119</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">66</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">56</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/zhangtingyu11"><i class="fab fa-github"></i><span>Follow Me</span></a></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>公告</span></div><div class="announcement_content">无</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#%E7%8E%AF%E5%A2%83%E5%AE%89%E8%A3%85"><span class="toc-number">1.</span> <span class="toc-text">环境安装</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%87%86%E5%A4%87%E6%95%B0%E6%8D%AE"><span class="toc-number">2.</span> <span class="toc-text">准备数据</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%AF%BC%E5%87%BAonnx%E6%9D%83%E9%87%8D"><span class="toc-number">3.</span> <span class="toc-text">导出Onnx权重</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%AF%BB%E5%8F%96%E6%95%B0%E6%8D%AE"><span class="toc-number">3.1.</span> <span class="toc-text">读取数据</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#loadpointcloudfromfile"><span class="toc-number">3.1.1.</span> <span class="toc-text">LoadPointCloudFromFile</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#loadpointcloudannotations"><span class="toc-number">3.1.2.</span> <span class="toc-text">LoadPointCloudAnnotations</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#preprocess"><span class="toc-number">3.1.3.</span> <span class="toc-text">Preprocess</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#voxelization"><span class="toc-number">3.1.4.</span> <span class="toc-text">Voxelization</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#assignlabel"><span class="toc-number">3.1.5.</span> <span class="toc-text">AssignLabel</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#reformat"><span class="toc-number">3.1.6.</span> <span class="toc-text">Reformat</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%B0%86%E6%95%B0%E6%8D%AE%E6%94%BE%E5%85%A5gpu%E4%B8%AD"><span class="toc-number">3.2.</span> <span class="toc-text">将数据放入GPU中</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%88%9B%E5%BB%BA%E6%A8%A1%E6%8B%9F%E6%95%B0%E6%8D%AE"><span class="toc-number">3.3.</span> <span class="toc-text">创建模拟数据</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#pillarfeatureextraction%E9%83%A8%E5%88%86%E7%9A%84%E6%A8%A1%E5%9E%8B%E4%BB%8B%E7%BB%8D"><span class="toc-number">3.4.</span> <span class="toc-text">PillarFeatureExtraction部分的模型介绍</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#pillarfeaturenet"><span class="toc-number">3.4.1.</span> <span class="toc-text">PillarFeatureNet</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%AF%BC%E5%87%BApillarfeatureextraction%E9%83%A8%E5%88%86%E6%A8%A1%E5%9E%8B"><span class="toc-number">3.5.</span> <span class="toc-text">导出PillarFeatureExtraction部分模型</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%B2%A1%E6%9C%89%E5%AF%BC%E5%87%BA%E7%9A%84%E9%83%A8%E5%88%86-pointpillarsscatter%E4%BB%8B%E7%BB%8D"><span class="toc-number">3.6.</span> <span class="toc-text">没有导出的部分(PointPillarsScatter介绍)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#rpn%E9%83%A8%E5%88%86%E6%A8%A1%E5%9E%8B%E4%BB%8B%E7%BB%8D"><span class="toc-number">3.7.</span> <span class="toc-text">RPN部分模型介绍</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#rpn"><span class="toc-number">3.7.1.</span> <span class="toc-text">RPN</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#block1"><span class="toc-number">3.7.1.1.</span> <span class="toc-text">Block1</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#deblock1"><span class="toc-number">3.7.1.2.</span> <span class="toc-text">DeBlock1</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#block2"><span class="toc-number">3.7.1.3.</span> <span class="toc-text">Block2</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#deblock2"><span class="toc-number">3.7.1.4.</span> <span class="toc-text">DeBlock2</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#block3"><span class="toc-number">3.7.1.5.</span> <span class="toc-text">Block3</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#deblock3"><span class="toc-number">3.7.1.6.</span> <span class="toc-text">DeBlock3</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#centerhead"><span class="toc-number">3.7.2.</span> <span class="toc-text">CenterHead</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%AF%BC%E5%87%BArpn%E9%83%A8%E5%88%86%E7%9A%84%E6%A8%A1%E5%9E%8B"><span class="toc-number">3.8.</span> <span class="toc-text">导出RPN部分的模型</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E7%AE%80%E5%8C%96%E6%A8%A1%E5%9E%8B"><span class="toc-number">4.</span> <span class="toc-text">简化模型</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#onnx-simplifier%E4%BB%8B%E7%BB%8D"><span class="toc-number">4.1.</span> <span class="toc-text">onnx-simplifier介绍</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%AE%A1%E7%AE%97%E5%9B%BE%E7%AE%80%E5%8C%96%E4%BB%A3%E7%A0%81"><span class="toc-number">4.2.</span> <span class="toc-text">计算图简化代码</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%AE%97%E5%AD%90%E7%AE%80%E5%8C%96"><span class="toc-number">4.3.</span> <span class="toc-text">算子简化</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%A8%A1%E5%9E%8B%E8%BE%93%E5%85%A5%E5%8F%98%E5%8C%96"><span class="toc-number">4.3.1.</span> <span class="toc-text">模型输入变化</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%B0%86%E5%85%A8%E8%BF%9E%E6%8E%A5%E5%B1%82%E8%BD%AC%E5%8C%96%E4%B8%BA%E5%8D%B7%E7%A7%AF%E5%B1%82"><span class="toc-number">4.4.</span> <span class="toc-text">将全连接层转化为卷积层</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%88%A0%E9%99%A4%E4%B8%80%E4%BA%9B%E4%B8%8D%E5%BF%85%E8%A6%81%E7%9A%84%E5%B1%82"><span class="toc-number">4.5.</span> <span class="toc-text">删除一些不必要的层</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%B0%86reducemax%E8%BD%AC%E5%8C%96%E4%B8%BAmaxpooling"><span class="toc-number">4.6.</span> <span class="toc-text">将ReduceMax转化为Maxpooling</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%B0%86torch-repeat%E8%BD%AC%E5%8C%96%E4%B8%BAtile"><span class="toc-number">4.7.</span> <span class="toc-text">将torch.repeat转化为Tile</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BF%AE%E6%94%B9%E6%8B%BC%E6%8E%A5%E7%9A%84%E7%BB%B4%E5%BA%A6"><span class="toc-number">4.8.</span> <span class="toc-text">修改拼接的维度</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%90%88%E5%B9%B6pfe%E5%92%8Crpn"><span class="toc-number">5.</span> <span class="toc-text">合并PFE和RPN</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%90%88%E5%B9%B6%E8%AE%A1%E7%AE%97%E5%9B%BE"><span class="toc-number">5.1.</span> <span class="toc-text">合并计算图</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%9E%84%E5%BB%BAscatternd%E6%9D%A5%E8%BF%9E%E6%8E%A5pfe%E5%92%8Crpn"><span class="toc-number">5.2.</span> <span class="toc-text">构建ScatterND来连接PFE和RPN</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#squeeze%E5%B1%82"><span class="toc-number">5.2.1.</span> <span class="toc-text">Squeeze层</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#tranpose1%E5%B1%82"><span class="toc-number">5.2.2.</span> <span class="toc-text">Tranpose1层</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#scatternd%E5%B1%82"><span class="toc-number">5.2.3.</span> <span class="toc-text">ScatterND层</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#transpose2%E5%B1%82"><span class="toc-number">5.2.4.</span> <span class="toc-text">Transpose2层</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#reshape%E5%B1%82"><span class="toc-number">5.2.5.</span> <span class="toc-text">Reshape层</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%A2%9D%E5%A4%96%E7%9A%84%E8%BE%93%E5%85%A5"><span class="toc-number">5.2.6.</span> <span class="toc-text">额外的输入</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%8A%82%E7%82%B9%E5%8A%A0%E5%85%A5%E8%AE%A1%E7%AE%97%E5%9B%BE"><span class="toc-number">5.2.7.</span> <span class="toc-text">节点加入计算图</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%9B%B4%E6%94%B9%E8%BE%93%E5%85%A5%E7%9A%84%E5%B0%BA%E5%AF%B8%E5%B9%B6%E5%AD%98%E5%82%A8%E6%A8%A1%E5%9E%8B"><span class="toc-number">5.3.</span> <span class="toc-text">更改输入的尺寸并存储模型</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E4%BD%BF%E7%94%A8tensorrt%E8%BF%9B%E8%A1%8C%E5%8A%A0%E9%80%9F"><span class="toc-number">6.</span> <span class="toc-text">使用TensorRT进行加速</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%B8%8B%E8%BD%BDtensorrt"><span class="toc-number">6.1.</span> <span class="toc-text">下载TensorRT</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%8E%B7%E5%8F%96%E7%82%B9%E4%BA%91%E6%95%B0%E6%8D%AE"><span class="toc-number">6.2.</span> <span class="toc-text">获取点云数据</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%BC%96%E8%AF%91tensorrt"><span class="toc-number">6.3.</span> <span class="toc-text">编译TensorRT</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BB%A3%E7%A0%81%E8%A7%A3%E6%9E%90"><span class="toc-number">6.4.</span> <span class="toc-text">代码解析</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#parseargs%E5%87%BD%E6%95%B0"><span class="toc-number">6.4.1.</span> <span class="toc-text">parseArgs函数</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%88%9D%E5%A7%8B%E5%8C%96%E5%8F%82%E6%95%B0%E5%87%BD%E6%95%B0initializesampleparams"><span class="toc-number">6.4.2.</span> <span class="toc-text">初始化参数函数initializeSampleParams</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#build%E5%87%BD%E6%95%B0"><span class="toc-number">6.4.3.</span> <span class="toc-text">build函数</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%88%9B%E5%BB%BAbuilder"><span class="toc-number">6.4.3.1.</span> <span class="toc-text">创建builder</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%88%9B%E5%BB%BA%E7%BD%91%E7%BB%9C"><span class="toc-number">6.4.3.2.</span> <span class="toc-text">创建网络</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%88%9B%E5%BB%BA%E9%85%8D%E7%BD%AE%E5%AF%B9%E8%B1%A1"><span class="toc-number">6.4.3.3.</span> <span class="toc-text">创建配置对象</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%88%9B%E5%BB%BAonnx%E8%A7%A3%E6%9E%90%E5%99%A8%E5%AF%B9%E8%B1%A1"><span class="toc-number">6.4.3.4.</span> <span class="toc-text">创建onnx解析器对象</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%A1%AB%E5%85%85%E7%BD%91%E7%BB%9C"><span class="toc-number">6.4.3.5.</span> <span class="toc-text">填充网络</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%9E%84%E5%BB%BAengine"><span class="toc-number">6.4.3.6.</span> <span class="toc-text">构建Engine</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E8%BE%93%E5%85%A5%E6%A8%A1%E5%9E%8B%E8%BE%93%E5%85%A5%E8%BE%93%E5%87%BA%E4%B8%AA%E6%95%B0%E7%AD%89%E4%BF%A1%E6%81%AF"><span class="toc-number">6.4.3.7.</span> <span class="toc-text">输入模型输入输出个数等信息</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#infer%E5%87%BD%E6%95%B0"><span class="toc-number">6.4.4.</span> <span class="toc-text">infer函数</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%88%9B%E5%BB%BA%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86%E5%99%A8"><span class="toc-number">6.4.4.1.</span> <span class="toc-text">创建内存管理器</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%88%9B%E5%BB%BA%E6%89%A7%E8%A1%8C%E4%B8%8A%E4%B8%8B%E6%96%87"><span class="toc-number">6.4.4.2.</span> <span class="toc-text">创建执行上下文</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E8%8E%B7%E5%8F%96voxel%E5%92%8Cvoxel%E7%9A%84%E7%B4%A2%E5%BC%95%E7%9A%84%E5%86%85%E5%AD%98"><span class="toc-number">6.4.4.3.</span> <span class="toc-text">获取voxel和voxel的索引的内存</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%9F%A5%E6%89%BE%E5%AF%B9%E5%BA%94%E7%9A%84%E6%95%B0%E6%8D%AE"><span class="toc-number">6.4.4.4.</span> <span class="toc-text">查找对应的数据</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E8%AF%BB%E5%8F%96%E7%82%B9%E4%BA%91%E6%95%B0%E6%8D%AE"><span class="toc-number">6.4.4.5.</span> <span class="toc-text">读取点云数据</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E9%A2%84%E5%A4%84%E7%90%86%E6%95%B0%E6%8D%AE"><span class="toc-number">6.4.4.6.</span> <span class="toc-text">预处理数据</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%B0%86%E8%BE%93%E5%85%A5%E6%8B%B7%E8%B4%9D%E8%87%B3gpu%E4%B8%8A"><span class="toc-number">6.4.4.7.</span> <span class="toc-text">将输入拷贝至GPU上</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E8%BF%90%E8%A1%8C%E6%A8%A1%E5%9E%8B"><span class="toc-number">6.4.4.8.</span> <span class="toc-text">运行模型</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%B0%86%E8%BE%93%E5%87%BA%E5%A4%8D%E5%88%B6%E5%88%B0cpu"><span class="toc-number">6.4.4.9.</span> <span class="toc-text">将输出复制到CPU</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%90%8E%E5%A4%84%E7%90%86%E6%95%B0%E6%8D%AE"><span class="toc-number">6.4.4.10.</span> <span class="toc-text">后处理数据</span></a></li></ol></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E6%80%BB%E7%BB%93"><span class="toc-number">7.</span> <span class="toc-text">总结</span></a></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2024/06/26/deep_learning/stanford_ml/chapter11/" title="斯坦福2021秋季·实用机器学习(第十一章)">斯坦福2021秋季·实用机器学习(第十一章)</a><time datetime="2024-06-26T07:04:34.000Z" title="发表于 2024-06-26 15:04:34">2024-06-26</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2024/06/26/deep_learning/stanford_ml/chapter10/" title="斯坦福2021秋季·实用机器学习(第十章)">斯坦福2021秋季·实用机器学习(第十章)</a><time datetime="2024-06-26T07:04:11.000Z" title="发表于 2024-06-26 15:04:11">2024-06-26</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2024/06/26/deep_learning/stanford_ml/chapter9/" title="斯坦福2021秋季·实用机器学习(第九章)">斯坦福2021秋季·实用机器学习(第九章)</a><time datetime="2024-06-26T07:03:24.000Z" title="发表于 2024-06-26 15:03:24">2024-06-26</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2024/06/26/deep_learning/stanford_ml/chapter5/" title="斯坦福2021秋季·实用机器学习(第五章)">斯坦福2021秋季·实用机器学习(第五章)</a><time datetime="2024-06-26T07:02:34.000Z" title="发表于 2024-06-26 15:02:34">2024-06-26</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2024/06/26/deep_learning/stanford_ml/chapter4/" title="斯坦福2021秋季·实用机器学习(第四章)">斯坦福2021秋季·实用机器学习(第四章)</a><time datetime="2024-06-26T06:56:43.000Z" title="发表于 2024-06-26 14:56:43">2024-06-26</time></div></div></div></div></div></div></main><footer id="footer" style="background-image: url('/img/top_img.png')"><div id="footer-wrap"><div class="copyright">&copy;2020 - 2024 By Grapymage</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><a id="to_comment" href="#post-comment" title="直达评论"><i class="fas fa-comments"></i></a><button id="go-up" type="button" title="回到顶部"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox/fancybox.umd.min.js"></script><div class="js-pjax"><script>(() => {
  const init = () => {
    twikoo.init(Object.assign({
      el: '#twikoo-wrap',
      envId: 'https://vercel-six-xi-75.vercel.app/',
      region: 'ap-shanghai',
      onCommentLoaded: () => {
        btf.loadLightbox(document.querySelectorAll('#twikoo .tk-content img:not(.tk-owo-emotion)'))
      }
    }, null))
  }

  const loadTwikoo = () => {
    if (typeof twikoo === 'object') setTimeout(init,0)
    else getScript('https://cdn.jsdelivr.net/npm/twikoo/dist/twikoo.all.min.js').then(init)
  }

  const getCount = () => {
    const countELement = document.getElementById('twikoo-count')
    if(!countELement) return
    twikoo.getCommentsCount({
      envId: 'https://vercel-six-xi-75.vercel.app/',
      region: 'ap-shanghai',
      urls: [window.location.pathname],
      includeReply: false
    }).then(res => {
      countELement.textContent = res[0].count
    }).catch(err => {
      console.error(err)
    })
  }

  if ('Twikoo' === 'Twikoo' || !false) {
    if (false) btf.loadComment(document.getElementById('twikoo-wrap'), loadTwikoo)
    else {
      loadTwikoo()
      
    }
  } else {
    window.loadOtherComment = loadTwikoo
  }
})()</script></div><script id="click-heart" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/dist/click-heart.min.js" async="async" mobile="true"></script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">搜索</span><span id="loading-status"></span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="is-center" id="loading-database"><i class="fas fa-spinner fa-pulse"></i><span>  数据库加载中</span></div><div class="search-wrap"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"/></div></div><hr/><div id="local-search-results"></div><div id="local-search-stats-wrap"></div></div></div><div id="search-mask"></div><script src="/js/search/local-search.js"></script></div></div></body></html>